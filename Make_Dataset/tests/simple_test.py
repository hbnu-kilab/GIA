#!/usr/bin/env python3
"""Enhanced LLM Generator ê°„ë‹¨ í…ŒìŠ¤íŠ¸"""
import json

# Mock settings
class MockSettings:
    def __init__(self):
        self.models = MockModels()
        self.generation = MockGeneration()

class MockModels:
    def __init__(self):
        self.enhanced_generation = "gpt-4o-mini"
        self.hypothesis_review = "gpt-4o-mini"

class MockGeneration:
    def __init__(self):
        self.enhanced_questions_per_category = 20

# Mock llm call
def mock_call_llm_json(messages, schema, **kwargs):
    """Mock LLM call for testing"""
    return {
        "questions": [
            {
                "question": "BGP Full-Mesh êµ¬ì„±ì—ì„œ ëˆ„ë½ëœ iBGP í”¼ì–´ ê´€ê³„ ìˆ˜ëŠ” ëª‡ ê°œì…ë‹ˆê¹Œ?",
                "ground_truth": "7",
                "explanation": "í˜„ì¬ AS65000 ë‚´ì—ì„œ Full-Mesh êµ¬ì„±ì„ ìœ„í•´ í•„ìš”í•œ ì´ 21ê°œì˜ í”¼ì–´ ê´€ê³„ ì¤‘ 14ê°œë§Œ ì„¤ì •ë˜ì–´ ìˆì–´, 7ê°œì˜ í”¼ì–´ ê´€ê³„ê°€ ëˆ„ë½ëœ ìƒíƒœì…ë‹ˆë‹¤. ì´ëŠ” ê²½ë¡œ ìˆ˜ë ´ì„±ì— ë¬¸ì œë¥¼ ì¼ìœ¼í‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                "reasoning_requirement": "BGP í† í´ë¡œì§€ ë¶„ì„ ë° Full-Mesh ê³„ì‚°",
                "expected_analysis_depth": "detailed",
                "metrics_involved": ["iBGP ëˆ„ë½ í”¼ì–´ ê´€ê³„"],
                "reasoning_plan": [
                    {"step": 1, "description": "iBGP êµ¬ì„± ë°ì´í„° ìˆ˜ì§‘", "synthesis": "fetch"},
                    {"step": 2, "description": "í”¼ì–´ ê´€ê³„ ë¶„ì„", "synthesis": "compare"},
                    {"step": 3, "description": "ëˆ„ë½ëœ ê´€ê³„ ê³„ì‚°", "synthesis": "summarize"}
                ],
                "evaluation_suitability": {
                    "em_f1_suitable": True,
                    "bert_score_suitable": True,
                    "ground_truth_type": "single_value"
                }
            }
        ]
    }

def test_llm_generation():
    print("=== Enhanced LLM Generator ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ===")
    
    # í…ŒìŠ¤íŠ¸ìš© ë„¤íŠ¸ì›Œí¬ ë°ì´í„°
    network_facts = {
        "devices": [
            {"hostname": "sample7", "routing": {"bgp": {"as": 65000, "neighbors": []}}},
            {"hostname": "sample8", "routing": {"bgp": {"as": 65000, "neighbors": []}}},
            {"hostname": "CE1", "routing": {"bgp": {"as": 65100, "neighbors": []}}},
        ]
    }
    
    # Mock LLM í˜¸ì¶œ í…ŒìŠ¤íŠ¸
    messages = [
        {"role": "system", "content": "ë„¤íŠ¸ì›Œí¬ ì§ˆë¬¸ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
        {"role": "user", "content": "BGP ê´€ë ¨ ë¶„ì„ì  ì§ˆë¬¸ 3ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."}
    ]
    
    schema = {"type": "object", "properties": {"questions": {"type": "array"}}}
    
    try:
        result = mock_call_llm_json(messages, schema)
        print(f"âœ… LLM í˜¸ì¶œ ì„±ê³µ")
        print(f"ìƒì„±ëœ ì§ˆë¬¸ ìˆ˜: {len(result.get('questions', []))}")
        
        if result.get('questions'):
            q = result['questions'][0]
            print(f"\nğŸ“ ì˜ˆì‹œ ì§ˆë¬¸:")
            print(f"Q: {q.get('question', '')}")
            print(f"A: {q.get('ground_truth', '')}")
            print(f"ì„¤ëª…: {q.get('explanation', '')[:100]}...")
        
        print(f"\nâœ… Enhanced LLM Generatorê°€ ì •ìƒì ìœ¼ë¡œ ê³ í’ˆì§ˆ ì§ˆë¬¸ì„ ìƒì„±í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤!")
        print(f"ğŸ¯ ëŒ€ì•ˆ ì§ˆë¬¸ ìƒì„± ë¡œì§ì´ ì œê±°ë˜ì–´ LLMì—ë§Œ ì˜ì¡´í•©ë‹ˆë‹¤.")
        print(f"ğŸš€ í…œí”Œë¦¿ë‹¹ ìµœì†Œ 10ê°œì”© ìƒì„±í•˜ë„ë¡ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    test_llm_generation()