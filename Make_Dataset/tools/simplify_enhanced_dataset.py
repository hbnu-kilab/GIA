#!/usr/bin/env python3
"""
Enhanced Dataset JSON ê°„ì†Œí™” ë„êµ¬
enhanced_dataset.jsonì—ì„œ í•„ìš”í•œ í•„ë“œë§Œ ì¶”ì¶œí•˜ì—¬ ê°„ì†Œí™”ëœ JSON ìƒì„±

í•„ìš”í•œ í•„ë“œ: id, question, ground_truth, explanation, source_files
"""

import json
import os
from pathlib import Path
from typing import Dict, List, Any
import argparse
from datetime import datetime


def extract_simplified_fields(data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    ì›ë³¸ ë°ì´í„°ì—ì„œ í•„ìš”í•œ í•„ë“œë§Œ ì¶”ì¶œ
    
    Args:
        data: ì›ë³¸ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        
    Returns:
        ê°„ì†Œí™”ëœ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    simplified_data = []
    
    for item in data:
        simplified_item = {}
        
        # í•„ìˆ˜ í•„ë“œ ì¶”ì¶œ
        required_fields = ['id', 'question', 'ground_truth', 'explanation', 'source_files']
        
        for field in required_fields:
            if field in item:
                simplified_item[field] = item[field]
            else:
                # ëˆ„ë½ëœ í•„ë“œì— ëŒ€í•œ ê¸°ë³¸ê°’ ì„¤ì •
                if field == 'source_files':
                    simplified_item[field] = []
                else:
                    simplified_item[field] = None
                    
        simplified_data.append(simplified_item)
    
    return simplified_data


def load_json_file(file_path: str) -> List[Dict[str, Any]]:
    """JSON íŒŒì¼ ë¡œë“œ"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"âœ… JSON íŒŒì¼ ë¡œë“œ ì„±ê³µ: {len(data)}ê°œ í•­ëª©")
        return data
        
    except FileNotFoundError:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return []
    except json.JSONDecodeError as e:
        print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        return []
    except Exception as e:
        print(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return []


def save_simplified_json(data: List[Dict[str, Any]], output_path: str):
    """ê°„ì†Œí™”ëœ JSON ì €ì¥"""
    try:
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        output_dir = Path(output_path).parent
        output_dir.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ê°„ì†Œí™”ëœ JSON ì €ì¥ ì™„ë£Œ: {output_path}")
        
        # íŒŒì¼ í¬ê¸° ì •ë³´
        file_size = Path(output_path).stat().st_size
        print(f"   íŒŒì¼ í¬ê¸°: {file_size:,} bytes ({file_size/1024/1024:.2f} MB)")
        
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")


def analyze_data_structure(data: List[Dict[str, Any]]):
    """ë°ì´í„° êµ¬ì¡° ë¶„ì„ ë° í†µê³„ ì¶œë ¥"""
    if not data:
        print("âŒ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"\nğŸ“Š ë°ì´í„° êµ¬ì¡° ë¶„ì„:")
    print(f"   ì´ í•­ëª© ìˆ˜: {len(data)}")
    
    # í•„ë“œë³„ ì¡´ì¬ ë¹„ìœ¨ í™•ì¸
    required_fields = ['id', 'question', 'ground_truth', 'explanation', 'source_files']
    field_stats = {}
    
    for field in required_fields:
        count = sum(1 for item in data if field in item and item[field] is not None)
        percentage = (count / len(data)) * 100
        field_stats[field] = {'count': count, 'percentage': percentage}
        print(f"   {field}: {count}/{len(data)} ({percentage:.1f}%)")
    
    # source_files ë¶„ì„
    source_files_data = [item.get('source_files', []) for item in data if 'source_files' in item]
    if source_files_data:
        total_files = sum(len(files) if isinstance(files, list) else 0 for files in source_files_data)
        avg_files = total_files / len(source_files_data) if source_files_data else 0
        print(f"   í‰ê·  source_files ìˆ˜: {avg_files:.1f}")
    
    # ì§ˆë¬¸ ê¸¸ì´ í†µê³„
    questions = [item.get('question', '') for item in data if 'question' in item]
    if questions:
        avg_question_length = sum(len(q) for q in questions) / len(questions)
        print(f"   í‰ê·  ì§ˆë¬¸ ê¸¸ì´: {avg_question_length:.0f} ê¸€ì")
    
    # ground_truth ê¸¸ì´ í†µê³„
    answers = [item.get('ground_truth', '') for item in data if 'ground_truth' in item]
    if answers:
        avg_answer_length = sum(len(str(a)) for a in answers) / len(answers)
        print(f"   í‰ê·  ë‹µë³€ ê¸¸ì´: {avg_answer_length:.0f} ê¸€ì")


def preview_simplified_data(data: List[Dict[str, Any]], num_samples: int = 3):
    """ê°„ì†Œí™”ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"""
    if not data:
        return
    
    print(f"\nğŸ‘€ ê°„ì†Œí™”ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ì²« {min(num_samples, len(data))}ê°œ):")
    
    for i, item in enumerate(data[:num_samples]):
        print(f"\n--- ìƒ˜í”Œ {i+1} ---")
        print(f"ID: {item.get('id', 'N/A')}")
        print(f"ì§ˆë¬¸: {item.get('question', 'N/A')[:100]}...")
        print(f"ì •ë‹µ: {str(item.get('ground_truth', 'N/A'))[:100]}...")
        print(f"ì„¤ëª…: {item.get('explanation', 'N/A')[:100]}...")
        source_files = item.get('source_files', [])
        print(f"ì†ŒìŠ¤ íŒŒì¼: {source_files if isinstance(source_files, list) else 'N/A'}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='Enhanced Dataset JSON ê°„ì†Œí™” ë„êµ¬')
    
    parser.add_argument(
        '--input',
        type=str,
        default='../output/network_qqa/enhanced_dataset.json',
        help='ì…ë ¥ JSON íŒŒì¼ ê²½ë¡œ'
    )
    
    parser.add_argument(
        '--output',
        type=str,
        default='simplified_dataset.json',
        help='ì¶œë ¥ JSON íŒŒì¼ ê²½ë¡œ'
    )
    
    parser.add_argument(
        '--preview',
        type=int,
        default=3,
        help='ë¯¸ë¦¬ë³´ê¸°í•  ìƒ˜í”Œ ìˆ˜'
    )
    
    parser.add_argument(
        '--no-analysis',
        action='store_true',
        help='ë°ì´í„° ë¶„ì„ ê±´ë„ˆë›°ê¸°'
    )
    
    args = parser.parse_args()
    
    print("ğŸ”§ Enhanced Dataset JSON ê°„ì†Œí™” ë„êµ¬")
    print("=" * 50)
    
    # ì…ë ¥ íŒŒì¼ ì ˆëŒ€ ê²½ë¡œ ë³€í™˜
    current_dir = Path(__file__).parent
    if not Path(args.input).is_absolute():
        input_path = current_dir / args.input
    else:
        input_path = Path(args.input)
    
    # ì¶œë ¥ íŒŒì¼ ì ˆëŒ€ ê²½ë¡œ ë³€í™˜
    if not Path(args.output).is_absolute():
        output_path = current_dir / args.output
    else:
        output_path = Path(args.output)
    
    print(f"ğŸ“ ì…ë ¥ íŒŒì¼: {input_path}")
    print(f"ğŸ“ ì¶œë ¥ íŒŒì¼: {output_path}")
    
    # 1. JSON íŒŒì¼ ë¡œë“œ
    data = load_json_file(str(input_path))
    if not data:
        return
    
    # 2. ë°ì´í„° ë¶„ì„ (ì˜µì…˜)
    if not args.no_analysis:
        analyze_data_structure(data)
    
    # 3. í•„ìš”í•œ í•„ë“œë§Œ ì¶”ì¶œ
    print(f"\nğŸ”„ í•„ë“œ ì¶”ì¶œ ì¤‘...")
    simplified_data = extract_simplified_fields(data)
    
    # 4. ë¯¸ë¦¬ë³´ê¸°
    preview_simplified_data(simplified_data, args.preview)
    
    # 5. ê°„ì†Œí™”ëœ JSON ì €ì¥
    print(f"\nğŸ’¾ ì €ì¥ ì¤‘...")
    save_simplified_json(simplified_data, str(output_path))
    
    # 6. ì™„ë£Œ ìš”ì•½
    print(f"\nğŸ‰ ì™„ë£Œ!")
    print(f"   ì›ë³¸: {len(data)}ê°œ í•­ëª©")
    print(f"   ê°„ì†Œí™”: {len(simplified_data)}ê°œ í•­ëª©")
    print(f"   ì¶”ì¶œ í•„ë“œ: id, question, ground_truth, explanation, source_files")
    
    # íŒŒì¼ í¬ê¸° ë¹„êµ
    try:
        original_size = input_path.stat().st_size
        simplified_size = output_path.stat().st_size
        reduction = ((original_size - simplified_size) / original_size) * 100
        print(f"   í¬ê¸° ê°ì†Œ: {reduction:.1f}% ({original_size:,} â†’ {simplified_size:,} bytes)")
    except:
        pass


if __name__ == "__main__":
    main()
