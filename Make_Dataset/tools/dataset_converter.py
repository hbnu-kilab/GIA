#!/usr/bin/env python3
"""
Enhanced Dataset ë³€í™˜ ìœ í‹¸ë¦¬í‹°
JSONì„ ë‹¤ì–‘í•œ í˜•íƒœë¡œ ë³€í™˜ (ê°„ì†Œí™”ëœ JSON, CSV, TSV ë“±)
"""

import json
import csv
from pathlib import Path
import argparse
from typing import Dict, List, Any, Optional


class DatasetConverter:
    """ë°ì´í„°ì…‹ ë³€í™˜ í´ë˜ìŠ¤"""
    
    def __init__(self, input_file: str):
        self.input_file = Path(input_file)
        self.data = []
        self.load_data()
    
    def load_data(self):
        """JSON ë°ì´í„° ë¡œë“œ"""
        try:
            with open(self.input_file, 'r', encoding='utf-8') as f:
                self.data = json.load(f)
            print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.data)}ê°œ í•­ëª©")
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.data = []
    
    def extract_fields(self, fields: List[str]) -> List[Dict[str, Any]]:
        """ì§€ì •ëœ í•„ë“œë§Œ ì¶”ì¶œ"""
        extracted_data = []
        
        for item in self.data:
            extracted_item = {}
            for field in fields:
                if field in item:
                    value = item[field]
                    # source_files ë¦¬ìŠ¤íŠ¸ëŠ” ë¬¸ìì—´ë¡œ ë³€í™˜
                    if field == 'source_files' and isinstance(value, list):
                        extracted_item[field] = ', '.join(value)
                    else:
                        extracted_item[field] = value
                else:
                    extracted_item[field] = None
            extracted_data.append(extracted_item)
        
        return extracted_data
    
    def to_simplified_json(self, output_file: str, fields: List[str] = None) -> bool:
        """ê°„ì†Œí™”ëœ JSONìœ¼ë¡œ ë³€í™˜"""
        if fields is None:
            fields = ['id', 'question', 'ground_truth', 'explanation', 'source_files']
        
        try:
            simplified_data = self.extract_fields(fields)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(simplified_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… ê°„ì†Œí™”ëœ JSON ì €ì¥: {output_file}")
            return True
            
        except Exception as e:
            print(f"âŒ JSON ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def to_csv(self, output_file: str, fields: List[str] = None) -> bool:
        """CSVë¡œ ë³€í™˜"""
        if fields is None:
            fields = ['id', 'question', 'ground_truth', 'explanation', 'source_files']
        
        try:
            simplified_data = self.extract_fields(fields)
            
            with open(output_file, 'w', newline='', encoding='utf-8-sig') as f:
                if simplified_data:
                    writer = csv.DictWriter(f, fieldnames=fields)
                    writer.writeheader()
                    writer.writerows(simplified_data)
            
            print(f"âœ… CSV ì €ì¥: {output_file}")
            return True
            
        except Exception as e:
            print(f"âŒ CSV ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def to_tsv(self, output_file: str, fields: List[str] = None) -> bool:
        """TSVë¡œ ë³€í™˜"""
        if fields is None:
            fields = ['id', 'question', 'ground_truth', 'explanation', 'source_files']
        
        try:
            simplified_data = self.extract_fields(fields)
            
            with open(output_file, 'w', newline='', encoding='utf-8') as f:
                if simplified_data:
                    writer = csv.DictWriter(f, fieldnames=fields, delimiter='\t')
                    writer.writeheader()
                    writer.writerows(simplified_data)
            
            print(f"âœ… TSV ì €ì¥: {output_file}")
            return True
            
        except Exception as e:
            print(f"âŒ TSV ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def to_benchmark_format(self, output_file: str) -> bool:
        """ë²¤ì¹˜ë§ˆí¬ í‰ê°€ìš© í˜•íƒœë¡œ ë³€í™˜"""
        try:
            benchmark_data = []
            
            for item in self.data:
                benchmark_item = {
                    'question': item.get('question', ''),
                    'ground_truth': item.get('ground_truth', ''),
                    'explanation': item.get('explanation', ''),
                    'id': item.get('id', ''),
                    'category': item.get('category', 'general'),
                    'complexity': item.get('complexity', 'medium'),
                    'source_files': ', '.join(item.get('source_files', [])) if isinstance(item.get('source_files'), list) else ''
                }
                benchmark_data.append(benchmark_item)
            
            with open(output_file, 'w', newline='', encoding='utf-8-sig') as f:
                if benchmark_data:
                    fieldnames = ['question', 'ground_truth', 'explanation', 'id', 'category', 'complexity', 'source_files']
                    writer = csv.DictWriter(f, fieldnames=fieldnames)
                    writer.writeheader()
                    writer.writerows(benchmark_data)
            
            print(f"âœ… ë²¤ì¹˜ë§ˆí¬ í˜•íƒœ CSV ì €ì¥: {output_file}")
            return True
            
        except Exception as e:
            print(f"âŒ ë²¤ì¹˜ë§ˆí¬ í˜•íƒœ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def get_statistics(self) -> Dict[str, Any]:
        """ë°ì´í„° í†µê³„ ì •ë³´"""
        if not self.data:
            return {}
        
        stats = {
            'total_items': len(self.data),
            'fields': {},
            'categories': {},
            'complexity': {},
            'source_files': {}
        }
        
        # í•„ë“œë³„ í†µê³„
        all_fields = set()
        for item in self.data:
            all_fields.update(item.keys())
        
        for field in all_fields:
            count = sum(1 for item in self.data if field in item and item[field] is not None)
            stats['fields'][field] = {
                'count': count,
                'percentage': (count / len(self.data)) * 100
            }
        
        # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
        categories = [item.get('category', 'unknown') for item in self.data]
        for category in set(categories):
            stats['categories'][category] = categories.count(category)
        
        # ë³µì¡ë„ë³„ í†µê³„
        complexities = [item.get('complexity', 'unknown') for item in self.data]
        for complexity in set(complexities):
            stats['complexity'][complexity] = complexities.count(complexity)
        
        # source_files í†µê³„
        all_source_files = []
        for item in self.data:
            source_files = item.get('source_files', [])
            if isinstance(source_files, list):
                all_source_files.extend(source_files)
        
        for source_file in set(all_source_files):
            stats['source_files'][source_file] = all_source_files.count(source_file)
        
        return stats
    
    def print_statistics(self):
        """í†µê³„ ì •ë³´ ì¶œë ¥"""
        stats = self.get_statistics()
        
        if not stats:
            print("âŒ í†µê³„ ì •ë³´ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"\nğŸ“Š ë°ì´í„°ì…‹ í†µê³„:")
        print(f"   ì´ í•­ëª© ìˆ˜: {stats['total_items']:,}")
        
        # í•„ë“œ í†µê³„
        print(f"\nğŸ“‹ í•„ë“œë³„ ì¡´ì¬ ë¹„ìœ¨:")
        for field, info in stats['fields'].items():
            print(f"   {field}: {info['count']}/{stats['total_items']} ({info['percentage']:.1f}%)")
        
        # ì¹´í…Œê³ ë¦¬ í†µê³„
        if stats['categories']:
            print(f"\nğŸ·ï¸ ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬:")
            for category, count in sorted(stats['categories'].items(), key=lambda x: x[1], reverse=True):
                print(f"   {category}: {count}ê°œ")
        
        # ë³µì¡ë„ í†µê³„
        if stats['complexity']:
            print(f"\nâš¡ ë³µì¡ë„ë³„ ë¶„í¬:")
            for complexity, count in sorted(stats['complexity'].items(), key=lambda x: x[1], reverse=True):
                print(f"   {complexity}: {count}ê°œ")
        
        # ìì£¼ ì‚¬ìš©ë˜ëŠ” ì†ŒìŠ¤ íŒŒì¼
        if stats['source_files']:
            print(f"\nğŸ“„ ìì£¼ ì°¸ì¡°ë˜ëŠ” ì†ŒìŠ¤ íŒŒì¼ (ìƒìœ„ 10ê°œ):")
            top_files = sorted(stats['source_files'].items(), key=lambda x: x[1], reverse=True)[:10]
            for source_file, count in top_files:
                print(f"   {source_file}: {count}ë²ˆ")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='Enhanced Dataset ë³€í™˜ ìœ í‹¸ë¦¬í‹°')
    
    parser.add_argument(
        '--input',
        type=str,
        default='../output/network_qqa/enhanced_dataset.json',
        help='ì…ë ¥ JSON íŒŒì¼ ê²½ë¡œ'
    )
    
    parser.add_argument(
        '--output-dir',
        type=str,
        default='.',
        help='ì¶œë ¥ ë””ë ‰í† ë¦¬'
    )
    
    parser.add_argument(
        '--formats',
        type=str,
        nargs='+',
        choices=['json', 'csv', 'tsv', 'benchmark'],
        default=['json', 'csv'],
        help='ë³€í™˜í•  í˜•íƒœ ì„ íƒ'
    )
    
    parser.add_argument(
        '--fields',
        type=str,
        nargs='+',
        default=['id', 'question', 'ground_truth', 'explanation', 'source_files'],
        help='ì¶”ì¶œí•  í•„ë“œ ì„ íƒ'
    )
    
    parser.add_argument(
        '--prefix',
        type=str,
        default='simplified_dataset',
        help='ì¶œë ¥ íŒŒì¼ëª… ì ‘ë‘ì‚¬'
    )
    
    parser.add_argument(
        '--stats',
        action='store_true',
        help='í†µê³„ ì •ë³´ ì¶œë ¥'
    )
    
    args = parser.parse_args()
    
    print("ğŸ”„ Enhanced Dataset ë³€í™˜ ìœ í‹¸ë¦¬í‹°")
    print("=" * 50)
    
    # ì…ë ¥ íŒŒì¼ ê²½ë¡œ ë³€í™˜
    current_dir = Path(__file__).parent
    if not Path(args.input).is_absolute():
        input_path = current_dir / args.input
    else:
        input_path = Path(args.input)
    
    print(f"ğŸ“ ì…ë ¥ íŒŒì¼: {input_path}")
    print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {args.output_dir}")
    print(f"ğŸ”§ ë³€í™˜ í˜•íƒœ: {args.formats}")
    print(f"ğŸ“‹ ì¶”ì¶œ í•„ë“œ: {args.fields}")
    
    # ë³€í™˜ê¸° ì´ˆê¸°í™”
    converter = DatasetConverter(str(input_path))
    
    if not converter.data:
        print("âŒ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # í†µê³„ ì •ë³´ ì¶œë ¥
    if args.stats:
        converter.print_statistics()
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ê° í˜•íƒœë¡œ ë³€í™˜
    results = []
    
    for format_type in args.formats:
        output_file = output_dir / f"{args.prefix}.{format_type}"
        
        if format_type == 'json':
            success = converter.to_simplified_json(str(output_file), args.fields)
        elif format_type == 'csv':
            success = converter.to_csv(str(output_file), args.fields)
        elif format_type == 'tsv':
            success = converter.to_tsv(str(output_file), args.fields)
        elif format_type == 'benchmark':
            success = converter.to_benchmark_format(str(output_file.with_suffix('.csv')))
        else:
            success = False
            
        results.append((format_type, success))
    
    # ê²°ê³¼ ìš”ì•½
    print(f"\nğŸ‰ ë³€í™˜ ì™„ë£Œ!")
    for format_type, success in results:
        status = "âœ…" if success else "âŒ"
        print(f"   {status} {format_type.upper()} ë³€í™˜")
    
    print(f"\nğŸ“Š ìš”ì•½:")
    print(f"   ì´ í•­ëª© ìˆ˜: {len(converter.data):,}")
    print(f"   ì¶”ì¶œëœ í•„ë“œ: {len(args.fields)}ê°œ")
    print(f"   ì„±ê³µí•œ ë³€í™˜: {sum(1 for _, success in results if success)}/{len(results)}")


if __name__ == "__main__":
    main()
