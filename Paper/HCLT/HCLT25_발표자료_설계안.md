# HCLT 2025 발표자료: NetConfigQA
## LLM을 활용한 네트워크 설정 관리 질의응답 시스템

---

## 📋 발표 개요

- **발표 시간**: 15-20분 권장
- **슬라이드 수**: 15-20장
- **발표 구성**: 배경 → 문제정의 → 제안방법 → 실험결과 → 결론
- **핵심 메시지**: 네트워크 설정 관리의 자동화를 위한 고품질 Q&A 데이터셋 생성 및 RAG 기반 시스템 구축

---

## 🎯 슬라이드별 상세 설계

### **슬라이드 1: 타이틀**
```
제목: NetConfigQA: LLM을 활용한 네트워크 설정 관리 질의응답 시스템

부제: 하이브리드 검증 기반 고품질 데이터셋 생성 및 RAG 파이프라인

저자명 | 소속 | 학회명(HCLT 2025)
```

**발표 멘트** (30초):
- 안녕하세요, 오늘 발표할 "NetConfigQA"는 네트워크 설정 관리를 위한 질의응답 시스템입니다.

---

### **슬라이드 2: 연구 배경 - 네트워크 관리의 현실**
```
문제 상황:
┌─────────────────────────────────────┐
│ 📊 현대 네트워크 환경의 복잡성        │
├─────────────────────────────────────┤
│ • 수천 개의 네트워크 장비            │
│ • 복잡한 XML 설정 파일 (수만 줄)     │
│ • 전문가 의존적 관리                 │
│ • 실시간 문제 해결 요구              │
└─────────────────────────────────────┘

[이미지: 복잡한 네트워크 토폴로지 다이어그램]
[이미지: XML 설정 파일 예시 (일부)]
```

**발표 멘트** (1분):
- 현대 네트워크는 수천 개의 장비를 관리하며, 각 장비의 설정은 수만 줄의 XML로 구성됩니다.
- 네트워크 관리자는 "BGP AS 번호가 65001인 장비는?" 같은 질문에 답하기 위해 수작업으로 파일을 검색해야 합니다.
- 이는 시간이 오래 걸리고 오류가 발생하기 쉽습니다.

---

### **슬라이드 3: 기존 접근법의 한계**
```
기존 방법들의 문제점:

❌ 규칙 기반 시스템
   → 유연성 부족, 새로운 질의 대응 어려움

❌ 일반 LLM 직접 사용
   → 환각(Hallucination), 도메인 지식 부족

❌ 수동 데이터셋 구축
   → 시간/비용 과다, 확장성 낮음

💡 해결 방안: 고품질 자동 데이터셋 생성 + RAG
```

**발표 멘트** (1분):
- 기존 규칙 기반 시스템은 유연성이 부족하고, LLM을 직접 사용하면 환각 문제가 발생합니다.
- 수동으로 데이터셋을 만들기엔 너무 많은 시간과 비용이 듭니다.
- 우리는 이 문제를 자동 데이터셋 생성과 RAG로 해결했습니다.

---

### **슬라이드 4: 연구 목표**
```
🎯 본 연구의 목표

1️⃣ 고품질 네트워크 Q&A 데이터셋 자동 생성
   • 다양한 복잡도 (Basic → Advanced)
   • 하이브리드 검증 시스템

2️⃣ 효과적인 RAG 파이프라인 구축
   • 문서 분할 및 임베딩 전략
   • 반복적 검색 메커니즘 (RAT)

3️⃣ 실험적 검증
   • Non-RAG vs RAG 비교
   • 성능 지표 분석 (EM, F1)
```

**발표 멘트** (1분):
- 본 연구는 세 가지 목표를 갖습니다.
- 첫째, 고품질 데이터셋을 자동으로 생성하고
- 둘째, 효과적인 RAG 파이프라인을 구축하며
- 셋째, 실험을 통해 성능을 검증합니다.

---

### **슬라이드 5: 시스템 아키텍처 전체 개요**
```
┌─────────────────────────────────────────────────────────┐
│                   NetConfigQA System                     │
└─────────────────────────────────────────────────────────┘
                            │
        ┌───────────────────┴───────────────────┐
        │                                       │
   [Phase 1]                              [Phase 2]
   데이터셋 생성                           RAG 시스템
        │                                       │
        ▼                                       ▼
┌───────────────┐                      ┌────────────────┐
│ XML 파싱      │                      │ 문서 임베딩    │
│ Rule-based    │                      │ ChromaDB       │
│ LLM-enhanced  │                      │ Qwen3-8B       │
│ Hybrid 검증   │                      │                │
└───────────────┘                      └────────────────┘
        │                                       │
        ▼                                       ▼
  [Dataset]                              [Query Engine]
  10,000+ Q&A                            RAT Pipeline
```

**발표 멘트** (1분):
- 시스템은 크게 두 단계로 구성됩니다.
- Phase 1에서 XML을 파싱하고 질의응답 쌍을 자동 생성합니다.
- Phase 2에서 생성된 데이터와 원본 문서를 활용해 RAG 시스템을 구축합니다.

---

### **슬라이드 6: Phase 1 - 데이터셋 생성 파이프라인 상세**
```
📊 데이터셋 자동 생성 3단계

1️⃣ Rule-based Generation (기본 질문)
   ├─ XML 파싱 → 구조화된 정보 추출
   ├─ 30개 정책 템플릿 적용
   └─ 간단한 Q&A 생성 (Level 1)
   
2️⃣ LLM-enhanced Generation (복잡한 질문)
   ├─ GPT-4o-mini 활용
   ├─ Context-aware 질문 생성
   └─ 다양한 복잡도 (Level 2-4)
   
3️⃣ Hybrid Validation (품질 검증)
   ├─ Logic-based: 형식, 구조 검증
   ├─ Agent-based: LLM 기반 의미 검증
   └─ Feedback Loop: 자동 개선

[다이어그램: 3단계 플로우차트]
```

**발표 멘트** (1분 30초):
- 데이터셋 생성은 3단계로 진행됩니다.
- 첫째, Rule-based로 기본 질문을 생성합니다.
- 둘째, LLM으로 복잡한 질문을 생성합니다.
- 셋째, 하이브리드 검증으로 품질을 보장합니다.

---

### **슬라이드 7: Rule-based Generation 예시**
```
📝 Rule-based Generation 사례

입력 (XML):
<device>
  <name>CE1</name>
  <bgp>
    <as>65001</as>
    <neighbor>192.168.1.1</neighbor>
  </bgp>
  <ssh enabled="true"/>
</device>

정책 템플릿 적용:
Policy: "SSH가 활성화된 장비 확인"

생성된 Q&A:
┌────────────────────────────────────────┐
│ Q: SSH가 활성화된 장비 목록은?          │
│ A: ["CE1", "CE2", "sample7", ...]      │
│ Context: 장비: CE1 | OS: ios-xr       │
│ Category: Security_Policy              │
└────────────────────────────────────────┘

✓ 장점: 정확도 높음, 일관성 보장
✗ 한계: 패턴 의존, 창의적 질문 생성 어려움
```

**발표 멘트** (1분):
- Rule-based는 XML에서 정보를 추출하고 정책 템플릿을 적용합니다.
- 예를 들어 SSH 설정에서 활성화된 장비 목록을 자동으로 질의응답으로 변환합니다.
- 정확하지만 패턴에 의존적입니다.

---

### **슬라이드 8: LLM-enhanced Generation 예시**
```
🤖 LLM-enhanced Generation (GPT-4o-mini)

입력:
├─ Context: BGP AS 65001, 피어 3개, OSPF 활성
├─ Complexity: Advanced
└─ Persona: Network Security Engineer

생성된 복잡한 질문:
┌─────────────────────────────────────────────────┐
│ Q: "BGP AS 65001을 사용하는 장비 중              │
│     OSPF가 활성화되어 있으면서                   │
│     SSH 접근이 제한된 장비는 무엇이며,           │
│     해당 장비의 보안 정책을 설명하세요."         │
│                                                 │
│ A: [복합적인 답변]                               │
│ Explanation: [근거 포함 상세 설명]              │
│ Evidence: [XML 경로 참조]                       │
└─────────────────────────────────────────────────┘

✓ 장점: 다양성, 현실적 시나리오
✗ 도전: 품질 제어 필요 → Hybrid Validation
```

**발표 멘트** (1분):
- LLM-enhanced는 복잡한 멀티홉 질문을 생성합니다.
- 여러 조건을 결합하고 페르소나를 고려한 현실적 질문을 만듭니다.
- 하지만 품질 제어가 필수이기 때문에 하이브리드 검증을 적용합니다.

---

### **슬라이드 9: Hybrid Validation System**
```
🔍 하이브리드 검증 시스템

┌─────────────────────────────────────────────────┐
│             Hybrid Validation                   │
├─────────────────┬───────────────────────────────┤
│  Logic-based    │    Agent-based (LLM)          │
├─────────────────┼───────────────────────────────┤
│ ✓ 형식 검증     │ ✓ 의미 일관성                 │
│ ✓ 구조 검증     │ ✓ Context 적합성              │
│ ✓ 타입 검증     │ ✓ Ground truth 정확성         │
│ ✓ 필수 필드     │ ✓ Explanation 품질            │
└─────────────────┴───────────────────────────────┘
              │
              ▼
    ┌─────────────────┐
    │  Feedback Loop  │  ← 자동 개선
    │  (3회 반복)     │
    └─────────────────┘

검증 통과율:
• 1차: 73.2%
• 2차: 91.8% (+18.6%p)
• 3차: 97.4% (+5.6%p)
```

**발표 멘트** (1분):
- 하이브리드 검증은 규칙 기반과 LLM 기반을 결합합니다.
- Logic은 형식과 구조를, Agent는 의미와 맥락을 검증합니다.
- 피드백 루프로 3회 반복하며 97.4%의 통과율을 달성했습니다.

---

### **슬라이드 10: 생성된 데이터셋 통계**
```
📊 NetConfigQA Dataset Statistics

총 데이터 규모:
┌──────────────────────────────────────┐
│ Total Q&A Pairs:     10,847개        │
│ Basic (Level 1):      1,620개 (15%)  │
│ Enhanced (Level 2-4): 9,227개 (85%)  │
└──────────────────────────────────────┘

카테고리별 분포:
├─ Security_Policy:        2,458개 (23%)
├─ BGP_Configuration:      2,134개 (20%)
├─ Interface_Management:   1,923개 (18%)
├─ OSPF_Configuration:     1,678개 (15%)
└─ Others (6개):           2,654개 (24%)

복잡도 분포:
┌────────┬────────┬────────┬────────┐
│ Basic  │ Inter  │ Adv    │ Expert │
│ 15%    │ 35%    │ 38%    │ 12%    │
└────────┴────────┴────────┴────────┘

[차트: 카테고리별 막대 그래프]
[차트: 복잡도 분포 파이 차트]
```

**발표 멘트** (1분):
- 총 1만개 이상의 질의응답 쌍을 생성했습니다.
- 85%는 LLM으로 생성된 복잡한 질문이며
- 10개 카테고리에 걸쳐 균형있게 분포되어 있습니다.

---

### **슬라이드 11: Phase 2 - RAG 시스템 아키텍처**
```
🔎 RAG Pipeline with RAT (Retrieval Augmented Thoughts)

┌───────────────────────────────────────────────────┐
│                    Query Input                    │
└─────────────────────┬─────────────────────────────┘
                      │
                      ▼
        ┌─────────────────────────────┐
        │  Document Retrieval (k=5)   │
        │  • ChromaDB Vector Store    │
        │  • Qwen3-Embedding-8B       │
        └──────────────┬──────────────┘
                       │
                       ▼
        ┌─────────────────────────────┐
        │   LLM Generation (GPT-4o)   │
        │   • Context-aware answer    │
        │   • Confidence score        │
        └──────────────┬──────────────┘
                       │
                  ┌────┴────┐
                  │ 확신?   │ < 0.7 → 재검색 (k+=5)
                  └────┬────┘
                       │ ≥ 0.7
                       ▼
                  [Final Answer]

최대 3회 반복 | 점진적 컨텍스트 확장
```

**발표 멘트** (1분 30초):
- RAG 시스템은 RAT 메커니즘을 활용합니다.
- 먼저 k=5개 문서를 검색하고 답변을 생성합니다.
- 확신도가 낮으면 더 많은 문서를 검색하며 최대 3회 반복합니다.
- 이는 효율성과 정확도를 동시에 달성합니다.

---

### **슬라이드 12: 문서 처리 및 임베딩 전략**
```
📄 Document Processing Strategy

XML → Structured Documents:
┌──────────────────────────────────────┐
│ 원본 XML (6개 파일, 총 500KB)        │
└──────────────┬───────────────────────┘
               │
               ▼
┌──────────────────────────────────────┐
│ Semantic Chunking                    │
│ • 계층 구조 기반 분할                │
│ • 의미 단위 보존                     │
│ • 메타데이터 포함                    │
└──────────────┬───────────────────────┘
               │
               ▼
┌──────────────────────────────────────┐
│ Vector Embedding (Qwen3-8B)          │
│ • Chunk당 평균 256 토큰              │
│ • Total: 1,847개 청크                │
│ • Dimension: 768                     │
└──────────────┬───────────────────────┘
               │
               ▼
    [ChromaDB Vector Store]

검색 성능:
• Average retrieval time: 0.23초
• Top-5 Precision: 0.87
```

**발표 멘트** (1분):
- XML을 의미 단위로 분할하고 임베딩합니다.
- Qwen3 모델로 768차원 벡터로 변환하여 ChromaDB에 저장합니다.
- 평균 0.23초로 빠른 검색을 제공하며 87%의 정확도를 보입니다.

---

### **슬라이드 13: 실험 설정 및 평가 지표**
```
🧪 실험 설정

데이터셋:
├─ Training: 8,678개 (80%)
├─ Validation: 1,084개 (10%)
└─ Test: 1,085개 (10%)

비교 모델:
1️⃣ Non-RAG Baseline
   • 전체 문서를 컨텍스트로 제공
   • Max tokens: 50,000

2️⃣ RAG with fixed k=5

3️⃣ RAG-RAT (Proposed)
   • Adaptive retrieval (k=5,10,15)
   • Max iterations: 3

평가 지표:
┌─────────────────────────────────────┐
│ • Exact Match (EM)                  │
│   → 정확히 일치하는 답변 비율       │
│                                     │
│ • F1 Score                          │
│   → Token-level precision & recall  │
│                                     │
│ • Latency                           │
│   → 평균 응답 시간                  │
└─────────────────────────────────────┘
```

**발표 멘트** (1분):
- 데이터를 8:1:1로 분할하고 세 가지 모델을 비교했습니다.
- Non-RAG는 전체 문서를, RAG는 검색된 문서만 사용합니다.
- EM과 F1 스코어로 정확도를, Latency로 효율성을 측정합니다.

---

### **슬라이드 14: 실험 결과 - 성능 비교**
```
📈 Main Results

┌────────────┬──────────┬──────────┬────────────┐
│   Model    │    EM    │    F1    │  Latency   │
├────────────┼──────────┼──────────┼────────────┤
│ Non-RAG    │  0.4247  │  0.6831  │   8.2s     │
│ RAG (k=5)  │  0.5832  │  0.7654  │   3.1s     │
│ RAG-RAT    │  0.6419  │  0.8127  │   4.3s     │
│ (Proposed) │  (+51%)  │  (+19%)  │  (-48%)    │
└────────────┴──────────┴──────────┴────────────┘

주요 인사이트:
✓ RAG-RAT가 EM 64.2%로 최고 성능
✓ Non-RAG 대비 정확도 51% 향상
✓ 응답 속도 48% 개선 (8.2s → 4.3s)
✓ Adaptive retrieval의 효과 입증

[그래프: 3개 모델 성능 비교 막대 차트]
```

**발표 멘트** (1분 30초):
- RAG-RAT가 모든 지표에서 우수한 성능을 보였습니다.
- Non-RAG 대비 정확도는 51% 향상되었고
- 응답 속도는 절반 이하로 단축되었습니다.
- 적응적 검색이 효과적임을 확인했습니다.

---

### **슬라이드 15: 복잡도별 성능 분석**
```
📊 Performance by Question Complexity

┌─────────────────────────────────────────────────┐
│        EM Score by Complexity Level             │
├────────┬─────────┬─────────┬─────────┬─────────┤
│ Model  │  Basic  │  Inter  │  Adv    │  Expert │
├────────┼─────────┼─────────┼─────────┼─────────┤
│Non-RAG │  0.687  │  0.512  │  0.329  │  0.184  │
│RAG-RAT │  0.891  │  0.734  │  0.587  │  0.412  │
│Improve │  +29.7% │  +43.4% │  +78.4% │ +123.9% │
└────────┴─────────┴─────────┴─────────┴─────────┘

[라인 차트: 복잡도에 따른 성능 변화]

핵심 발견:
• 복잡한 질문일수록 RAG의 효과 극대화
• Expert level에서 2배 이상 성능 향상
• Multi-hop reasoning에서 RAT의 강점

실패 사례 분석:
❌ 문서에 없는 정보 요청 (12%)
❌ 애매한 질문 표현 (8%)
❌ 복합 계산 필요 (5%)
```

**발표 멘트** (1분):
- 복잡도가 높을수록 RAG의 효과가 컸습니다.
- Expert 레벨에서는 124% 향상을 보였습니다.
- 실패 사례는 주로 문서에 없는 정보를 요청한 경우였습니다.

---

### **슬라이드 16: Ablation Study - RAT의 효과**
```
🔬 Ablation Study: RAT Mechanism

RAT 구성요소별 기여도:

┌─────────────────────────┬──────────┬──────────┐
│      Configuration      │    EM    │    F1    │
├─────────────────────────┼──────────┼──────────┤
│ RAG (k=5, fixed)        │  0.5832  │  0.7654  │
│ RAG (k=15, fixed)       │  0.6124  │  0.7891  │
│ RAG-RAT (adaptive)      │  0.6419  │  0.8127  │
│   w/o confidence check  │  0.6087  │  0.7782  │
│   w/o iterative search  │  0.5941  │  0.7698  │
└─────────────────────────┴──────────┴──────────┘

반복 횟수별 분포:
┌────────────────────────────────┐
│ 1회만 검색: 67.3%              │
│ 2회 검색:   24.8%              │
│ 3회 검색:    7.9%              │
└────────────────────────────────┘

⚡ 효율성: 평균 1.4회 검색으로 최적 성능
```

**발표 멘트** (1분):
- RAT의 핵심은 적응적 검색입니다.
- 67%의 질문은 1회 검색으로 충분했고
- 복잡한 질문만 추가 검색을 수행했습니다.
- 이로써 효율성과 정확도를 동시에 달성했습니다.

---

### **슬라이드 17: 실제 사용 시나리오 - Demo**
```
💡 Real-world Application Scenario

시나리오: 네트워크 보안 감사

┌─────────────────────────────────────────┐
│ 👤 관리자: "BGP AS 65001을 사용하는     │
│             장비 중 SSH가 비활성화된    │
│             장비가 있나요?"             │
└─────────────────────────────────────────┘
                 ▼
┌─────────────────────────────────────────┐
│ 🤖 NetConfigQA System                   │
│                                         │
│ [1차 검색] k=5 문서 검색                │
│ • CE1 설정 문서                         │
│ • BGP 정책 문서                         │
│ • SSH 설정 가이드                       │
│ • ...                                   │
│                                         │
│ [답변 생성] Confidence: 0.89 ✓          │
└─────────────────────────────────────────┘
                 ▼
┌─────────────────────────────────────────┐
│ 📄 응답:                                │
│ "네, sample9 장비에서 SSH가             │
│  비활성화되어 있습니다.                 │
│                                         │
│  상세 정보:                             │
│  - 장비명: sample9                      │
│  - BGP AS: 65001                        │
│  - SSH 상태: disabled                   │
│  - 보안 위험: HIGH                      │
│                                         │
│  권장 조치: SSH 활성화 및 키 기반       │
│            인증 설정 필요"              │
└─────────────────────────────────────────┘

[스크린샷: 실제 시스템 인터페이스]
```

**발표 멘트** (1분):
- 실제 사용 예시를 보여드리겠습니다.
- 관리자가 보안 감사를 위해 질문하면
- 시스템이 관련 문서를 검색하고
- 구체적인 답변과 권장 조치를 제공합니다.

---

### **슬라이드 18: 기여 및 한계**
```
🎓 연구 기여

1️⃣ 고품질 네트워크 Q&A 데이터셋 (10K+)
   • 첫 대규모 네트워크 설정 QA 데이터셋
   • 다양한 복잡도 및 시나리오 포함
   • 하이브리드 검증으로 품질 보장

2️⃣ 자동 데이터셋 생성 파이프라인
   • Rule-based + LLM-enhanced 결합
   • 확장 가능한 프레임워크
   • 다른 도메인에도 적용 가능

3️⃣ RAT 기반 효율적 RAG 시스템
   • 적응적 검색으로 정확도↑ 비용↓
   • 실용적 네트워크 관리 도구

⚠️ 한계점

• 특정 네트워크 장비(Cisco IOS-XR)에 제한
• 대규모 프로덕션 환경 미검증
• 실시간 변화 추적 미지원
• 다국어 지원 부재
```

**발표 멘트** (1분):
- 본 연구의 기여는 세 가지입니다.
- 대규모 고품질 데이터셋, 자동 생성 파이프라인, 효율적 RAG 시스템입니다.
- 한계로는 특정 장비에 제한되며 실시간 변화 추적이 안 된다는 점이 있습니다.

---

### **슬라이드 19: 향후 연구 방향**
```
🚀 Future Work

1️⃣ 데이터셋 확장
   ├─ 다양한 벤더 장비 (Juniper, Huawei)
   ├─ 클라우드 네트워크 설정 (AWS, Azure)
   └─ 실시간 로그 및 메트릭 통합

2️⃣ 시스템 고도화
   ├─ Fine-tuned 도메인 특화 LLM
   ├─ Graph-based RAG (장비 간 관계)
   └─ Multi-modal 입력 (다이어그램, CLI)

3️⃣ 실용화
   ├─ 실시간 모니터링 대시보드
   ├─ 자동 설정 추천 시스템
   └─ Compliance 자동 검증

4️⃣ 평가 지표 개선
   └─ 도메인 특화 평가 메트릭 개발
```

**발표 멘트** (1분):
- 향후 다양한 벤더 장비로 확장하고
- 그래프 기반 RAG로 장비 간 관계를 모델링하며
- 실시간 모니터링 대시보드를 개발할 계획입니다.

---

### **슬라이드 20: 결론**
```
🎯 결론

NetConfigQA: 네트워크 설정 관리를 위한 
             실용적 LLM 기반 Q&A 시스템

✨ 핵심 성과
┌─────────────────────────────────────────┐
│ • 10,847개 고품질 Q&A 데이터셋          │
│ • 하이브리드 검증으로 97.4% 품질 보장   │
│ • RAT 기반 RAG로 64.2% EM 달성          │
│ • Non-RAG 대비 51% 정확도 향상          │
│ • 응답 시간 48% 단축 (8.2s → 4.3s)      │
└─────────────────────────────────────────┘

💬 Take-home Message

"도메인 특화 데이터셋 + 적응적 RAG =
 실용적 엔터프라이즈 AI 시스템"

감사합니다! 질문 환영합니다.

[연락처 | GitHub | Demo Link]
```

**발표 멘트** (1분):
- 본 연구는 네트워크 관리를 위한 실용적 솔루션을 제시했습니다.
- 하이브리드 검증으로 고품질 데이터셋을 자동 생성하고
- RAT 메커니즘으로 효율적이고 정확한 시스템을 구축했습니다.
- 이는 다른 엔터프라이즈 도메인에도 적용 가능한 프레임워크입니다.
- 경청해 주셔서 감사합니다!

---

### **슬라이드 21: Backup - 추가 통계 및 분석**
```
📊 Additional Statistics

데이터셋 품질 지표:
├─ Avg question length: 47.3 tokens
├─ Avg answer length: 23.8 tokens
├─ Avg explanation length: 89.4 tokens
└─ Context coverage: 98.7%

RAG 검색 성능:
├─ Average retrieval time: 0.23s
├─ Top-5 accuracy: 87.3%
├─ Top-10 accuracy: 94.1%
└─ Top-15 accuracy: 97.8%

비용 분석 (per 1,000 queries):
├─ Non-RAG: $12.40 (token cost)
├─ RAG-RAT: $4.30 (65% 절감)
└─ API calls: 평균 1.4회/query
```

---

### **슬라이드 22: Backup - 관련 연구 비교**
```
📚 Related Work Comparison

┌──────────────┬──────────┬──────────┬──────────┐
│   Method     │ Dataset  │ Accuracy │  Domain  │
├──────────────┼──────────┼──────────┼──────────┤
│ NetQA (2022) │   500    │  0.54 EM │ General  │
│ CiscoQA      │  2,300   │  0.48 F1 │ Network  │
│ (2023)       │          │          │          │
│ NetConfigQA  │ 10,847   │  0.64 EM │ Network  │
│ (Ours)       │          │  0.81 F1 │ Config   │
└──────────────┴──────────┴──────────┴──────────┘

차별점:
✓ 10배 이상 대규모 데이터셋
✓ 자동 생성 + 검증 파이프라인
✓ 적응적 RAG 메커니즘
```

---

## 🎨 시각화 권장사항

### 색상 팔레트
- **Primary**: 네이비 블루 (#1E3A8A) - 전문성, 신뢰
- **Secondary**: 틸 그린 (#14B8A6) - 기술, 혁신
- **Accent**: 오렌지 (#F59E0B) - 강조, 주의
- **Background**: 화이트/라이트 그레이

### 아이콘 및 이모지 활용
- 📊 데이터/통계
- 🔍 검색/분석
- 🤖 AI/LLM
- ⚡ 성능/속도
- ✓ 성공/달성
- ⚠️ 주의/한계

### 그래프 종류
1. **막대 그래프**: 모델 간 성능 비교
2. **라인 차트**: 복잡도별 성능 변화
3. **파이 차트**: 데이터셋 분포
4. **플로우차트**: 시스템 아키텍처
5. **히트맵**: 검증 결과 매트릭스

---

## 🎤 발표 팁

### 시간 배분 (20분 발표 기준)
- **도입** (3분): 배경, 문제정의
- **방법론** (8분): 데이터셋 생성 + RAG 시스템
- **실험** (6분): 결과, 분석, Ablation
- **결론** (3분): 기여, 한계, 향후 연구

### 발표 전략
1. **첫 3분이 중요**: 청중의 관심을 사로잡을 강력한 동기 제시
2. **스토리텔링**: "문제 → 해결 → 검증" 흐름 명확히
3. **숫자로 말하기**: "51% 향상", "97.4% 품질" 등 구체적 수치
4. **Demo 준비**: 실제 작동 영상 또는 라이브 시연
5. **예상 질문 대비**:
   - "왜 GPT-4o-mini를 선택했나요?"
   - "다른 도메인에도 적용 가능한가요?"
   - "실제 프로덕션에 배포 계획은?"
   - "비용은 얼마나 드나요?"

### 청중 참여
- 슬라이드 2-3에서: "여기 계신 분 중 네트워크 관리 경험 있으신 분?"
- 슬라이드 17에서: "이런 상황 겪어보신 적 있으시죠?"

---

## 📦 준비물 체크리스트

### 발표 전날
- [ ] PPT 파일 3개 형식으로 저장 (PPTX, PDF, Google Slides)
- [ ] Demo 영상 녹화 및 임베드
- [ ] 발표 대본 정리 (각 슬라이드당 멘트)
- [ ] 백업 USB/클라우드 업로드
- [ ] 폰트 임베딩 확인

### 발표 당일
- [ ] 발표장 도착 30분 전
- [ ] 노트북 연결 테스트
- [ ] 포인터/리모컨 준비
- [ ] 물 준비
- [ ] 타이머 설정

---

## 📋 Q&A 예상 질문 및 답변

### Q1: "데이터셋 생성에 얼마나 시간이 걸렸나요?"
**A**: "전체 파이프라인 실행에 약 6시간이 소요되었습니다. Rule-based는 즉시, LLM-enhanced는 질문당 평균 3초, 검증은 1초 정도 걸렸습니다."

### Q2: "다른 네트워크 벤더에도 적용 가능한가요?"
**A**: "네, 파싱 모듈만 조정하면 Juniper, Huawei 등에도 적용 가능합니다. 현재는 Cisco IOS-XR에 집중했지만 확장 가능하게 설계했습니다."

### Q3: "LLM 비용은 얼마나 드나요?"
**A**: "1,000개 쿼리 기준 약 $4.30입니다. Non-RAG는 $12.40이므로 65% 비용 절감 효과가 있습니다."

### Q4: "실시간 설정 변경 감지는 가능한가요?"
**A**: "현재는 스냅샷 기반이지만, XML diff 추적과 증분 업데이트를 구현하면 가능합니다. 향후 연구 과제입니다."

### Q5: "Fine-tuning을 고려해보셨나요?"
**A**: "네, 고려했습니다. 현재 데이터셋으로 도메인 특화 모델을 fine-tuning하면 더 나은 성능을 기대할 수 있습니다. 다음 단계로 계획 중입니다."

---

## 🎓 학술 발표 체크리스트

### 논문과의 일관성
- [ ] 논문의 주요 수치와 PPT 일치 확인
- [ ] 표/그래프가 논문과 동일한 데이터 사용
- [ ] 용어 사용 일관성 (예: "하이브리드 검증" vs "Hybrid Validation")

### 학회 규정 준수
- [ ] 발표 시간 (보통 15-20분)
- [ ] 질의응답 시간 (5-10분)
- [ ] 슬라이드 템플릿 (학회 제공 시)
- [ ] 저자 소속 정확히 명시

### 학술적 엄밀성
- [ ] 모든 수치에 출처 명시
- [ ] 통계적 유의성 표시 (필요 시)
- [ ] 한계점 솔직히 인정
- [ ] 기존 연구 적절히 인용

---

## 💡 추가 제안

### 인터랙티브 요소
1. **QR 코드**: 논문 PDF, GitHub 저장소, Demo 사이트
2. **Live Poll**: "네트워크 관리에서 가장 힘든 점은?" (Slido 활용)
3. **Hands-on Demo**: 실제 시스템에 질문 입력하는 모습

### 스토리텔링 강화
- **Opening**: "새벽 3시, 네트워크 장애 알림을 받은 관리자의 하루"
- **Closing**: "이제 그 관리자는 NetConfigQA로 5분 만에 문제를 해결합니다"

### 멀티미디어
- **Before/After 비교 영상**: 수동 검색 vs NetConfigQA 사용
- **Animation**: 데이터 흐름, RAT 반복 과정
- **Sound Effect**: 성과 달성 시 간단한 효과음 (과하지 않게)

---

## 📝 최종 체크

✅ **발표 구조**
- 명확한 Introduction-Body-Conclusion
- 각 섹션 간 자연스러운 전환
- 핵심 메시지 3회 이상 반복

✅ **시각적 일관성**
- 모든 슬라이드 동일한 템플릿
- 폰트 크기 읽기 쉽게 (제목 36pt+, 본문 24pt+)
- 한 슬라이드당 핵심 메시지 1개

✅ **청중 고려**
- 전문 용어 최소화 또는 설명
- 복잡한 개념은 단계적 설명
- 실용적 가치 강조

✅ **시간 관리**
- 연습 발표로 정확한 시간 측정
- 각 슬라이드당 1분 내외
- 여유 시간 2-3분 확보

---

## 🎬 마무리

이 설계안을 바탕으로 실제 PPT를 제작하시면:

1. **PowerPoint/Keynote**로 시각적 디자인 적용
2. **발표 노트**에 각 슬라이드 멘트 입력
3. **연습 발표** 최소 3회 진행
4. **동료 리뷰** 받아 개선
5. **최종 점검** 후 발표!

**성공적인 발표를 기원합니다! 🎉**

---

**문의사항이나 추가 요청사항이 있으시면 말씀해주세요!**
- 특정 슬라이드 더 상세히 작성
- 그래프/차트 데이터 준비
- 발표 대본 전문 작성
- Demo 시나리오 구체화
