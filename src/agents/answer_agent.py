from typing import Dict, Any, List, Union, Set, Tuple
import json
import re

from utils.builder_core import BuilderCore
from utils.llm_adapter import _call_llm_json
from utils.config_manager import get_settings

settings = get_settings()

class AnswerAgent:
    """Reasoning plan executor that synthesizes a descriptive answer."""

    def __init__(self, network_facts: Dict[str, Any]):
        self.network_facts = network_facts
        self.builder = BuilderCore(network_facts.get("devices", []))
        self.evidence: Dict[str, Any] = {}
        self.referenced_files: Set[str] = set()

    def execute_plan(
        self,
        question: str,
        plan: Union[List[Dict[str, Any]], str],
        answer_type: str = "long",
    ) -> Dict[str, Any]:
        """Execute reasoning steps and return ground truth, explanation and source files."""
        self.evidence = {}
        self.referenced_files = set()

        if isinstance(plan, str):
            ground_truth, explanation = self._synthesize_text_answer(question, plan, answer_type)
            return {
                "ground_truth": ground_truth,
                "explanation": explanation,
                "source_files": sorted(self.referenced_files),
            }

        if not plan:
            ground_truth, explanation = self._synthesize_text_answer(
                question, "No reasoning plan provided", answer_type
            )
            return {
                "ground_truth": ground_truth,
                "explanation": explanation,
                "source_files": sorted(self.referenced_files),
            }

        if isinstance(plan, list):
            for step in sorted(
                plan, key=lambda x: x.get("step", 0) if isinstance(x, dict) else 0
            ):
                if not isinstance(step, dict):
                    continue
                metric = step.get("required_metric")
                if not metric:
                    continue
                params = step.get("metric_params") or {}
                try:
                    result, files = self.builder.calculate_metric(metric, params)
                except Exception as e:
                    result = f"error: {e}"
                    files = []
                self.evidence[f"step_{step.get('step')}_{metric}"] = result
                self.referenced_files.update(files)
            ground_truth, explanation = self._synthesize_json_answer(
                question, plan, answer_type
            )
            return {
                "ground_truth": ground_truth,
                "explanation": explanation,
                "source_files": sorted(self.referenced_files),
            }

        ground_truth, explanation = self._synthesize_text_answer(
            question, str(plan), answer_type
        )
        return {
            "ground_truth": ground_truth,
            "explanation": explanation,
            "source_files": sorted(self.referenced_files),
        }

    def _synthesize_text_answer(
        self, question: str, plan_text: str, answer_type: str = "long"
    ) -> Tuple[Any, str]:
        """Handle text-based reasoning plans."""
        potential_metrics = [
            # ì‹¤ì œ êµ¬í˜„ëœ ë©”íŠ¸ë¦­ë“¤ë§Œ í¬í•¨
            "ssh_missing_count", "ssh_enabled_devices", "ssh_missing_devices",
            "ibgp_missing_pairs_count", "ibgp_fullmesh_ok", "ibgp_missing_pairs",
            "vrf_without_rt_count", "vrf_without_rt_pairs", "l2vpn_unidir_count",
            "aaa_enabled_devices", "aaa_missing_devices", "ssh_present_bool",
            "bgp_neighbor_count", "interface_count", "ospf_area0_if_count"
        ]

        relevant_metrics: List[str] = []
        plan_lower = plan_text.lower()

        question_lower = question.lower()
        if "ssh" in question_lower:
            relevant_metrics.extend(["ssh_missing_count", "ssh_enabled_devices", "ssh_missing_devices", "ssh_present_bool"])
        if "bgp" in question_lower:
            relevant_metrics.extend(["ibgp_missing_pairs_count", "ibgp_fullmesh_ok", "ibgp_missing_pairs", "bgp_neighbor_count"])
        if "vrf" in question_lower:
            relevant_metrics.extend(["vrf_without_rt_count", "vrf_without_rt_pairs"])
        if "aaa" in question_lower:
            relevant_metrics.extend(["aaa_enabled_devices", "aaa_missing_devices"])
        if "l2vpn" in question_lower:
            relevant_metrics.extend(["l2vpn_unidir_count"])
        if "interface" in question_lower or "ì¸í„°í˜ì´ìŠ¤" in question_lower:
            relevant_metrics.extend(["interface_count"])
        if "ospf" in question_lower:
            relevant_metrics.extend(["ospf_area0_if_count"])

        if not relevant_metrics:
            relevant_metrics = ["ssh_enabled_devices", "ibgp_missing_pairs_count"]

        for metric in relevant_metrics:
            try:
                result, files = self.builder.calculate_metric(metric)
                self.evidence[metric] = result
                self.referenced_files.update(files)
            except Exception as e:
                self.evidence[metric] = f"error: {e}"

        return self._synthesize_json_answer(question, plan_text, answer_type)

    def _synthesize_json_answer(
        self,
        question: str,
        plan: Union[List[Dict[str, Any]], str],
        answer_type: str = "long",
    ) -> Tuple[Any, str]:
        """Return structured ground truth and explanation derived from LLM output."""
        schema = {
            "title": "StructuredAnswer",
            "type": "object",
            "properties": {
                "ground_truth": {
                    "type": ["string", "boolean", "number", "array", "null"],
                    "description": """
                **[ë§¤ìš° ì¤‘ìš”]** ì§ˆë¬¸ì— ëŒ€í•œ í•µì‹¬ì ì´ê³  ì§ì ‘ì ì¸ 'ì •ë‹µ' ê·¸ ìì²´.
                - ì§ˆë¬¸ì´ 'ê°œìˆ˜'ë¥¼ ë¬¼ìœ¼ë©´: ìˆ«ì (ì˜ˆ: 0, 1, 5)
                - ì§ˆë¬¸ì´ 'ëª©ë¡'ì„ ë¬¼ìœ¼ë©´: ë¬¸ìì—´ì˜ ë°°ì—´ (ì˜ˆ: ["CE1", "CE2"])
                - ì§ˆë¬¸ì´ 'ì´ë¦„'ì´ë‚˜ 'ê°’' í•˜ë‚˜ë¥¼ ë¬¼ìœ¼ë©´: ë¬¸ìì—´ (ì˜ˆ: "CE1")
                - ì§ˆë¬¸ì´ 'ë¶„ì„'ì´ë‚˜ 'ì„¤ëª…'ì„ ìš”êµ¬í•˜ë©´: ì™„ë²½í•œ ì„œìˆ í˜• ë¬¸ì¥ (ì˜ˆ: "iBGP í’€ë©”ì‹œê°€ ì •ìƒ ì‘ë™í•˜ì—¬...")
                - **ì ˆëŒ€ 'ì •ë‹µì„ ì°¾ëŠ” ê³¼ì •'ì„ ì„œìˆ í•˜ì§€ ë§ ê²ƒ.**
                """,
                },
                "explanation": {
                    "type": "string",
                    "description": "ìœ„ ground_truthê°€ ì™œ ì •ë‹µì¸ì§€, ì œê³µëœ ì¦ê±°(evidence)ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸íˆ ì„¤ëª…í•˜ëŠ” ë¬¸ì¥.",
                },
            },
            "required": ["ground_truth", "explanation"],
        }

        evidence_summary = (
            self._format_evidence() if self.evidence else "No evidence available."
        )

        system_prompt = f"""
ë‹¹ì‹ ì€ ë„¤íŠ¸ì›Œí¬ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ 'ì •ë‹µ'ê³¼ 'í•´ì„¤'ì„ ì—„ê²©í•˜ê²Œ ë¶„ë¦¬í•˜ì—¬ ìƒì„±í•˜ëŠ” AI ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.

**[ë‹¹ì‹ ì˜ ì„ë¬´]**
1. ì£¼ì–´ì§„ 'ì§ˆë¬¸'ê³¼ 'ì¦ê±°(evidence)'ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
2. ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ íŒŒì•…í•˜ì—¬, ì±„ì ì— ì‚¬ìš©ë  ìˆ˜ ìˆëŠ” ëª…í™•í•œ **'ground_truth'(ì •ë‹µ)**ë¥¼ ë¨¼ì € ê²°ì •í•©ë‹ˆë‹¤.
3. ê·¸ ë‹¤ìŒ, í•´ë‹¹ ì •ë‹µì´ ë‚˜ì˜¨ ì´ìœ ë¥¼ **'explanation'(í•´ì„¤)**ìœ¼ë¡œ ìƒì„¸íˆ ì„œìˆ í•©ë‹ˆë‹¤.

**[ì—„ê²©í•œ ê·œì¹™]**
- `ground_truth` í•„ë“œì—ëŠ” ì ˆëŒ€, ì ˆëŒ€ ì„¤ëª…ì„ ë„£ì§€ ë§ˆì„¸ìš”. ì˜¤ì§ 'ì •ë‹µ' ê°’ë§Œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
- ì§ˆë¬¸ì´ íŠ¹ì • ìˆ«ìë‚˜ ëª©ë¡ì„ ìš”êµ¬í•˜ë©´, `ground_truth`ëŠ” ë°˜ë“œì‹œ í•´ë‹¹ í˜•ì‹(ìˆ«ì, ë°°ì—´)ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.
- `explanation`ì€ í•­ìƒ ì™„ì „í•œ ë¬¸ì¥ í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤.
"""

        user_prompt = f"""
- **ì§ˆë¬¸**: {question}
- **ì§ˆë¬¸ ìœ í˜• íŒíŠ¸**: {answer_type}
- **ë¶„ì„ëœ ì¦ê±°**: 
{evidence_summary}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, JSON ìŠ¤í‚¤ë§ˆì˜ ê·œì¹™ì— ë”°ë¼ 'ground_truth'ì™€ 'explanation'ì„ ìƒì„±í•˜ì„¸ìš”.
'ì§ˆë¬¸ ìœ í˜• íŒíŠ¸'ê°€ 'short'ì´ë©´ `ground_truth`ëŠ” ìˆ«ì, ë¦¬ìŠ¤íŠ¸, ë‹¨ì¼ ë¬¸ìì—´ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.
"""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ]

        try:
            data = _call_llm_json(
                messages,
                schema,
                temperature=0.0,
                model=settings.models.answer_synthesis,
                max_output_tokens=700,
                use_responses_api=False,
            )
            if isinstance(data, dict):
                ground_truth = data.get("ground_truth")
                explanation = data.get("explanation", "")
                if ground_truth is not None:
                    return ground_truth, explanation
        except Exception as e:
            import logging
            logging.warning(f"AnswerAgent LLM synthesis failed: {e}")

        # í´ë°±: ê°„ë‹¨ LLM í˜¸ì¶œ ë˜ëŠ” í…œí”Œë¦¿ ìƒì„±ìœ¼ë¡œ ë‹µë³€ í™•ë³´
        try:
            fallback_answer = self._simple_llm_call(question, evidence_summary)
            return fallback_answer, evidence_summary
        except Exception:
            # ìµœí›„ í´ë°±: ì¦ê±° ìš”ì•½ì„ explanationìœ¼ë¡œ, ê°„ë‹¨í•œ ë¬¸ì¥ ìƒì„±
            return (
                f"ì§ˆë¬¸ì— ëŒ€í•œ ë¶„ì„ ê²°ê³¼ëŠ” ì¦ê±° ìš”ì•½ì„ ì°¸ì¡°í•˜ì„¸ìš”. ì£¼ìš” ì¦ê±°: {evidence_summary[:200]}...",
                evidence_summary,
            )

    def _extract_ground_truth(self, eval_targets: Dict[str, Any], explanation: str) -> Any:
        """Infer ground truth from explanation text or eval_targets."""
        ce_matches = re.findall(r"CE\d+", explanation)
        if ce_matches:
            unique: List[str] = []
            for m in ce_matches:
                if m not in unique:
                    unique.append(m)
            return unique[0] if len(unique) == 1 else unique

        if any(kw in explanation for kw in ["ì—†ìŠµë‹ˆë‹¤", "ì—†ìŒ", "0ê°œ"]):
            f1 = eval_targets.get("f1_score") if isinstance(eval_targets, dict) else None
            if isinstance(f1, list):
                return []
            return 0

        num_match = re.search(r"(-?\d+)", explanation)
        if num_match:
            try:
                return int(num_match.group(1))
            except ValueError:
                pass

        if isinstance(eval_targets, dict):
            f1 = eval_targets.get("f1_score")
            if isinstance(f1, list) and f1:
                return f1
            return eval_targets.get("exact_match")

        return ""

    def _format_evidence(self) -> str:
        """Evidenceë¥¼ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ í¬ë§·íŒ…"""
        if not self.evidence:
            return "ìˆ˜ì§‘ëœ ì¦ê±°ê°€ ì—†ìŠµë‹ˆë‹¤."

        formatted = []
        for key, value in self.evidence.items():
            if key.startswith('step_'):
                parts = key.split('_')
                if len(parts) >= 3:
                    step_num = parts[1]
                    metric_name = '_'.join(parts[2:])
                    formatted.append(f"â€¢ {step_num}ë‹¨ê³„ ({metric_name}): {self._format_value(value)}")
                else:
                    formatted.append(f"â€¢ {key}: {self._format_value(value)}")
            else:
                korean_name = self._translate_metric_name(key)
                formatted.append(f"â€¢ {korean_name}: {self._format_value(value)}")
        return '\n'.join(formatted)

    def _translate_metric_name(self, metric_name: str) -> str:
        translations = {
            # SSH ê´€ë ¨
            'ssh_enabled_devices': 'SSH í™œì„±í™”ëœ ì¥ë¹„',
            'ssh_missing_devices': 'SSH ë¯¸ì„¤ì • ì¥ë¹„',
            'ssh_missing_count': 'SSH ë¯¸ì„¤ì • ì¥ë¹„ ìˆ˜',
            'ssh_all_enabled_bool': 'SSH ì „ì²´ í™œì„±í™” ì—¬ë¶€',
            'ssh_present_bool': 'SSH ì„¤ì • ì¡´ì¬ ì—¬ë¶€',
            'ssh_version_text': 'SSH ë²„ì „',
            'ssh_acl_applied_check': 'SSH ACL ì ìš© ì—¬ë¶€',
            
            # BGP ê´€ë ¨
            'ibgp_fullmesh_ok': 'iBGP í’€ë©”ì‹œ ì •ìƒ ì—¬ë¶€',
            'ibgp_missing_pairs': 'iBGP ëˆ„ë½ í˜ì–´',
            'ibgp_missing_pairs_count': 'iBGP ëˆ„ë½ í˜ì–´ ìˆ˜',
            'ibgp_under_peered_devices': 'iBGP í”¼ì–´ ë¶€ì¡± ì¥ë¹„',
            'ibgp_under_peered_count': 'iBGP í”¼ì–´ ë¶€ì¡± ì¥ë¹„ ìˆ˜',
            'neighbor_list_ibgp': 'iBGP ì´ì›ƒ ëª©ë¡',
            'neighbor_list_ebgp': 'eBGP ì´ì›ƒ ëª©ë¡',
            'ebgp_remote_as_map': 'eBGP ì›ê²© AS ë§¤í•‘',
            'ibgp_update_source_missing_set': 'iBGP ì—…ë°ì´íŠ¸ ì†ŒìŠ¤ ëˆ„ë½',
            'bgp_local_as_numeric': 'BGP ë¡œì»¬ AS ë²ˆí˜¸',
            'bgp_neighbor_count': 'BGP ì´ì›ƒ ìˆ˜',
            'bgp_inconsistent_as_count': 'BGP AS ë¶ˆì¼ì¹˜ ìˆ˜',
            'bgp_peer_count': 'BGP í”¼ì–´ ìˆ˜',
            'bgp_advertised_prefixes_list': 'BGP ê´‘ê³  í”„ë¦¬í”½ìŠ¤ ëª©ë¡',
            
            # VRF ê´€ë ¨
            'vrf_rd_map': 'VRF RD ë§¤í•‘',
            'vrf_rt_list_per_device': 'VRF RT ëª©ë¡',
            'vrf_without_rt_pairs': 'RT ë¯¸ì„¤ì • VRF ìŒ',
            'vrf_without_rt_count': 'RT ë¯¸ì„¤ì • VRF ìˆ˜',
            'vrf_interface_bind_count': 'VRF ì¸í„°í˜ì´ìŠ¤ ë°”ì¸ë”© ìˆ˜',
            'vrf_rd_format_invalid_set': 'RD í˜•ì‹ ì˜¤ë¥˜ VRF',
            'vrf_bind_map': 'VRF ë°”ì¸ë”© ë§¤í•‘',
            'vrf_names_set': 'VRF ì´ë¦„ ëª©ë¡',
            'vrf_count': 'VRF ê°œìˆ˜',
            
            # L2VPN ê´€ë ¨
            'l2vpn_pairs': 'L2VPN í˜ì–´',
            'l2vpn_unidirectional_pairs': 'ë‹¨ë°©í–¥ L2VPN í˜ì–´',
            'l2vpn_unidir_count': 'ë‹¨ë°©í–¥ L2VPN ìˆ˜',
            'l2vpn_pwid_mismatch_pairs': 'PW-ID ë¶ˆì¼ì¹˜ L2VPN í˜ì–´',
            'l2vpn_mismatch_count': 'L2VPN ë¶ˆì¼ì¹˜ ìˆ˜',
            'l2vpn_pw_id_set': 'L2VPN PW-ID ëª©ë¡',
            
            # OSPF ê´€ë ¨
            'ospf_proc_ids': 'OSPF í”„ë¡œì„¸ìŠ¤ ID',
            'ospf_area0_if_list': 'OSPF Area 0 ì¸í„°í˜ì´ìŠ¤ ëª©ë¡',
            'ospf_area0_if_count': 'OSPF Area 0 ì¸í„°í˜ì´ìŠ¤ ìˆ˜',
            'ospf_area_set': 'OSPF ì˜ì—­ ëª©ë¡',
            'ospf_area_count': 'OSPF ì˜ì—­ ìˆ˜',
            'ospf_process_ids_set': 'OSPF í”„ë¡œì„¸ìŠ¤ ID ëª©ë¡',
            
            # AAA ê´€ë ¨
            'aaa_enabled_devices': 'AAA í™œì„±í™”ëœ ì¥ë¹„',
            'aaa_missing_devices': 'AAA ë¯¸ì„¤ì • ì¥ë¹„',
            'aaa_present_bool': 'AAA ì„¤ì • ì¡´ì¬ ì—¬ë¶€',
            'password_policy_present_bool': 'íŒ¨ìŠ¤ì›Œë“œ ì •ì±… ì¡´ì¬ ì—¬ë¶€',
            
            # ì¸í„°í˜ì´ìŠ¤ ê´€ë ¨
            'interface_count': 'ì¸í„°í˜ì´ìŠ¤ ìˆ˜',
            'interface_ip_map': 'ì¸í„°í˜ì´ìŠ¤ IP ë§¤í•‘',
            'interface_vlan_set': 'VLAN ëª©ë¡',
            'subinterface_count': 'ì„œë¸Œì¸í„°í˜ì´ìŠ¤ ìˆ˜',
            'interface_mop_xenabled_bool': 'MOP xenabled ì„¤ì •',
            
            # ì‹œìŠ¤í…œ ê´€ë ¨
            'system_hostname_text': 'í˜¸ìŠ¤íŠ¸ë„¤ì„',
            'system_version_text': 'ì‹œìŠ¤í…œ ë²„ì „',
            'system_timezone_text': 'ì‹œê°„ëŒ€',
            'system_user_count': 'ì‹œìŠ¤í…œ ì‚¬ìš©ì ìˆ˜',
            'system_user_list': 'ì‹œìŠ¤í…œ ì‚¬ìš©ì ëª©ë¡',
            'system_mgmt_address_text': 'ê´€ë¦¬ IP ì£¼ì†Œ',
            'system_users_detail_map': 'ì‹œìŠ¤í…œ ì‚¬ìš©ì ìƒì„¸',
            'ios_config_register_text': 'Config Register ê°’',
            'logging_buffered_severity_text': 'ë¡œê¹… ë²„í¼ ì‹¬ê°ë„',
            'http_server_enabled_bool': 'HTTP ì„œë²„ í™œì„±í™”',
            'ip_forward_protocol_nd_bool': 'IP Forward Protocol ND',
            'ip_cef_enabled_bool': 'IP CEF í™œì„±í™”',
            'vty_first_last_text': 'VTY ë¼ì¸ ë²”ìœ„',
            'vty_login_mode_text': 'VTY ë¡œê·¸ì¸ ëª¨ë“œ',
            'vty_password_secret_text': 'VTY íŒ¨ìŠ¤ì›Œë“œ ì‹œí¬ë¦¿',
            'vty_transport_input_text': 'VTY ì „ì†¡ ì…ë ¥',
            
            # ì„œë¹„ìŠ¤ ê´€ë ¨
            'mpls_ldp_present_bool': 'MPLS LDP ì¡´ì¬ ì—¬ë¶€',
            'rt_export_count': 'RT Export ìˆ˜',
            'rt_import_count': 'RT Import ìˆ˜',
            'qos_policer_applied_interfaces_list': 'QoS Policer ì ìš© ì¸í„°í˜ì´ìŠ¤',
            
            # ëª…ë ¹ì–´ ê´€ë ¨
            'cmd_show_bgp_summary': 'BGP ìš”ì•½ ëª…ë ¹ì–´',
            'cmd_show_ip_interface_brief': 'IP ì¸í„°í˜ì´ìŠ¤ ìš”ì•½ ëª…ë ¹ì–´',
            'cmd_show_ip_route_ospf': 'OSPF ë¼ìš°íŒ… í…Œì´ë¸” ëª…ë ¹ì–´',
            'cmd_show_processes_cpu': 'CPU í”„ë¡œì„¸ìŠ¤ ëª…ë ¹ì–´',
            'cmd_show_l2vpn_vc': 'L2VPN VC ëª…ë ¹ì–´',
            'cmd_show_ip_ospf_neighbor': 'OSPF ì´ì›ƒ ëª…ë ¹ì–´',
            'cmd_show_users': 'ì‚¬ìš©ì ëª©ë¡ ëª…ë ¹ì–´',
            'cmd_show_logging': 'ë¡œê¹… ëª…ë ¹ì–´',
            'cmd_ssh_direct_access': 'SSH ì§ì ‘ ì ‘ì† ëª…ë ¹ì–´',
            'cmd_set_static_route': 'ì •ì  ë¼ìš°íŒ… ì„¤ì • ëª…ë ¹ì–´',
            'cmd_set_bgp_routemap': 'BGP ë¼ìš°íŠ¸ë§µ ì„¤ì • ëª…ë ¹ì–´',
            'cmd_set_interface_description': 'ì¸í„°í˜ì´ìŠ¤ ì„¤ëª… ì„¤ì • ëª…ë ¹ì–´',
            'cmd_create_vrf_and_assign': 'VRF ìƒì„± ë° í• ë‹¹ ëª…ë ¹ì–´',
            'cmd_set_ospf_cost': 'OSPF ë¹„ìš© ì„¤ì • ëª…ë ¹ì–´',
            'cmd_set_vty_acl': 'VTY ACL ì„¤ì • ëª…ë ¹ì–´',
            'cmd_set_hostname': 'í˜¸ìŠ¤íŠ¸ë„¤ì„ ì„¤ì • ëª…ë ¹ì–´',
            'cmd_ssh_proxy_jump': 'SSH í”„ë¡ì‹œ ì í”„ ëª…ë ¹ì–´',
        }
        return translations.get(metric_name, metric_name)

    def _format_value(self, value) -> str:
        if isinstance(value, bool):
            return "âœ… ì •ìƒ" if value else "âŒ ë¬¸ì œ"
        elif isinstance(value, (int, float)) and value == 0:
            return "0 (ë¬¸ì œì—†ìŒ)"
        elif isinstance(value, list):
            if len(value) == 0:
                return "ì—†ìŒ"
            elif len(value) <= 3:
                return f"{', '.join(map(str, value))}"
            else:
                return f"{', '.join(map(str, value[:3]))}... (ì´ {len(value)}ê°œ)"
        elif isinstance(value, str) and value.startswith("error:"):
            return f"âš ï¸ {value}"
        else:
            return str(value)

    def _generate_template_answer(self, question: str, evidence_summary: str) -> str:
        if "ì¦ê±°ê°€ ì—†ìŠµë‹ˆë‹¤" in evidence_summary:
            return f"""\nì§ˆë¬¸ "{question}"ì— ëŒ€í•œ ë¶„ì„ì„ ì‹œë„í–ˆì§€ë§Œ, ê´€ë ¨ ì¦ê±°ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤.\n\nì´ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì›ì¸ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:\nâ€¢ ë„¤íŠ¸ì›Œí¬ ì„¤ì • ë°ì´í„°ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ\nâ€¢ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë©”íŠ¸ë¦­ì´ ì•„ì§ êµ¬í˜„ë˜ì§€ ì•ŠìŒ\nâ€¢ ë°ì´í„° íŒŒì‹± ê³¼ì •ì—ì„œ ì˜¤ë¥˜ ë°œìƒ\n\në” êµ¬ì²´ì ì¸ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ë„¤íŠ¸ì›Œí¬ ì„¤ì • íŒŒì¼ê³¼ ì§ˆë¬¸ì˜ ì í•©ì„±ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.\n"""

        return f"""\nì§ˆë¬¸ "{question}"ì— ëŒ€í•œ ë¶„ì„ ê²°ê³¼:\n\nìˆ˜ì§‘ëœ ì¦ê±°:\n{evidence_summary}\n\nìœ„ ì¦ê±°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë„¤íŠ¸ì›Œí¬ì˜ í˜„ì¬ ìƒíƒœë¥¼ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nêµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ ì„¤ì • ìƒíƒœë¥¼ í†µí•´ í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ë„ì¶œí•  ìˆ˜ ìˆìœ¼ë©°,\në¬¸ì œê°€ ë°œê²¬ëœ ê²½ìš° ì ì ˆí•œ í•´ê²°ì±…ì„ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.\n\nğŸ’¡ ë” ì •í™•í•œ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” LLM ê¸°ë°˜ ë‹µë³€ ìƒì„± ê¸°ëŠ¥ì„ í™œìš©í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n"""

    def _simple_llm_call(self, question: str, evidence_summary: str) -> str:
        try:
            simple_prompt = f"""ë„¤íŠ¸ì›Œí¬ ì „ë¬¸ê°€ë¡œì„œ ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.\n\nì§ˆë¬¸: {question}\n\nì¦ê±°:\n{evidence_summary}\n\nìœ„ ì¦ê±°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•´ ì „ë¬¸ì ì´ê³  êµ¬ì²´ì ì¸ ë‹µë³€ì„ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”. ì¦ê±°ì˜ ìˆ˜ì¹˜ì™€ ìƒíƒœë¥¼ ì–¸ê¸‰í•˜ë©° ì‹¤ë¬´ì ì¸ ê´€ì ì—ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""

            schema = {
                "title": "SimpleAnswer",
                "type": "object",
                "properties": {"answer": {"type": "string"}},
                "required": ["answer"],
                "additionalProperties": False,
            }

            messages = [{"role": "user", "content": simple_prompt}]
            data = _call_llm_json(
                messages,
                schema,
                temperature=0.1,
                model=settings.models.answer_synthesis,
                max_output_tokens=600,
                use_responses_api=False,
            )
            answer = data.get("answer") if isinstance(data, dict) else None
            if isinstance(answer, str):
                print(f"âœ… ê°„ë‹¨í•œ LLM í˜¸ì¶œ ì„±ê³µ (ê¸¸ì´: {len(answer)}ì)")
                return answer
        except Exception as e:
            print(f"ğŸš¨ ê°„ë‹¨í•œ LLM í˜¸ì¶œë„ ì‹¤íŒ¨: {e}")
        return self._generate_template_answer(question, evidence_summary)
