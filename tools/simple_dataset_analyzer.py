"""
ë„¤íŠ¸ì›Œí¬ êµ¬ì„± íŒŒì‹± ë°ì´í„°ì…‹ ë…¼ë¬¸ìš© ê°„ë‹¨ ë¶„ì„ ë„êµ¬
Network Configuration Parsing Dataset Analysis for Academic Paper (Simple Version)
"""

import json
import matplotlib.pyplot as plt
from pathlib import Path
from collections import Counter, defaultdict
from typing import Dict, List, Any
import statistics

class SimpleNetworkDatasetAnalyzer:
    def __init__(self, dataset_path: str):
        """ë°ì´í„°ì…‹ ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        self.dataset_path = Path(dataset_path)
        self.data = self._load_dataset()
        self.output_dir = self.dataset_path.parent / "analysis_results"
        self.output_dir.mkdir(exist_ok=True)
        
    def _load_dataset(self) -> Dict[str, Any]:
        """ë°ì´í„°ì…‹ ë¡œë“œ"""
        with open(self.dataset_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def generate_analysis(self):
        """ë¶„ì„ ìˆ˜í–‰ ë° ë…¼ë¬¸ìš© ì‹œê°í™” ìƒì„±"""
        print("ğŸ” ë°ì´í„°ì…‹ ë¶„ì„ ì‹œì‘...")
        
        # ê¸°ë³¸ í†µê³„ ìˆ˜ì§‘
        stats = self._collect_basic_stats()
        
        # ê·¸ë˜í”„ ìƒì„±
        self._create_figures(stats)
        
        # í‘œ ë°ì´í„° ìƒì„±
        self._create_tables(stats)
        
        # ë¦¬í¬íŠ¸ ìƒì„±
        self._create_report(stats)
        
        print(f"âœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ëŠ” {self.output_dir}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return stats
    
    def _collect_basic_stats(self):
        """ê¸°ë³¸ í†µê³„ ìˆ˜ì§‘"""
        all_samples = (self.data.get('train', []) + 
                      self.data.get('validation', []) + 
                      self.data.get('test', []))
        
        # ê¸°ë³¸ í†µê³„
        train_count = len(self.data.get('train', []))
        val_count = len(self.data.get('validation', []))
        test_count = len(self.data.get('test', []))
        total_count = len(all_samples)
        
        # ì¹´í…Œê³ ë¦¬ ë¶„ì„
        category_counts = Counter(sample['category'] for sample in all_samples)
        
        # ë³µì¡ë„ ë¶„ì„
        complexity_counts = Counter(sample['complexity'] for sample in all_samples)
        
        # ë‹µë³€ íƒ€ì… ë¶„ì„
        answer_type_counts = Counter(sample['answer_type'] for sample in all_samples)
        
        # í† í´ë¡œì§€ íŠ¹í™” ë¶„ì„
        topology_categories = {
            'Interface_Inventory', 'Routing_Inventory', 'VRF_Consistency',
            'BGP_Consistency', 'OSPF_Consistency', 'L2VPN_Consistency',
            'Basic_Info', 'System_Inventory'
        }
        
        topology_count = sum(category_counts[cat] for cat in topology_categories if cat in category_counts)
        general_count = total_count - topology_count
        
        # ì§ˆë¬¸/ë‹µë³€ ê¸¸ì´ ë¶„ì„
        question_lengths = []
        answer_lengths = []
        
        for sample in all_samples:
            question_lengths.append(len(sample['question'].split()))
            
            gt = sample['ground_truth']
            if isinstance(gt, (list, dict)):
                gt_str = str(gt)
            else:
                gt_str = str(gt)
            answer_lengths.append(len(gt_str.split()))
        
        return {
            'total_samples': total_count,
            'train_samples': train_count,
            'val_samples': val_count,
            'test_samples': test_count,
            'category_counts': dict(category_counts),
            'complexity_counts': dict(complexity_counts),
            'answer_type_counts': dict(answer_type_counts),
            'topology_count': topology_count,
            'general_count': general_count,
            'topology_ratio': topology_count / total_count if total_count > 0 else 0,
            'avg_question_length': statistics.mean(question_lengths),
            'avg_answer_length': statistics.mean(answer_lengths),
            'question_lengths': question_lengths,
            'answer_lengths': answer_lengths,
            'device_count': self.data['metadata']['pipeline_results']['parsing']['device_count']
        }
    
    def _create_figures(self, stats):
        """ë…¼ë¬¸ìš© Figure ìƒì„±"""
        # Figure 1: ë°ì´í„°ì…‹ êµ¬ì„± ê°œìš”
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
        
        # 1. Train/Val/Test ë¶„í• 
        split_data = [stats['train_samples'], stats['val_samples'], stats['test_samples']]
        labels = ['Train', 'Validation', 'Test']
        colors = ['#3498db', '#e74c3c', '#2ecc71']
        
        ax1.pie(split_data, labels=labels, autopct='%1.1f%%', colors=colors, startangle=90)
        ax1.set_title('Dataset Split Distribution', fontsize=14, fontweight='bold')
        
        # 2. í† í´ë¡œì§€ íŠ¹í™” vs ì¼ë°˜
        topo_data = [stats['topology_count'], stats['general_count']]
        topo_labels = ['Topology-Specific', 'General Network']
        topo_colors = ['#e74c3c', '#3498db']
        
        ax2.pie(topo_data, labels=topo_labels, autopct='%1.1f%%', colors=topo_colors, startangle=90)
        ax2.set_title('Question Focus Distribution', fontsize=14, fontweight='bold')
        
        # 3. ë‹µë³€ íƒ€ì… ë¶„í¬
        answer_types = list(stats['answer_type_counts'].keys())
        answer_counts = list(stats['answer_type_counts'].values())
        
        ax3.bar(answer_types, answer_counts, color=['#1abc9c', '#e67e22'])
        ax3.set_title('Answer Type Distribution', fontsize=14, fontweight='bold')
        ax3.set_ylabel('Count')
        
        # 4. ë³µì¡ë„ ë¶„í¬
        complexity_order = ['basic', 'analytical', 'synthetic', 'diagnostic', 'scenario']
        complexity_data = [stats['complexity_counts'].get(comp, 0) for comp in complexity_order]
        
        ax4.bar(complexity_order, complexity_data, color='#34495e')
        ax4.set_title('Question Complexity Distribution', fontsize=14, fontweight='bold')
        ax4.set_ylabel('Count')
        ax4.tick_params(axis='x', rotation=45)
        
        plt.tight_layout()
        plt.savefig(self.output_dir / 'figure1_dataset_overview.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # Figure 2: ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))
        
        # ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬
        categories = list(stats['category_counts'].keys())
        counts = list(stats['category_counts'].values())
        
        # ìƒìœ„ 10ê°œ ì¹´í…Œê³ ë¦¬ë§Œ í‘œì‹œ
        if len(categories) > 10:
            sorted_items = sorted(zip(categories, counts), key=lambda x: x[1], reverse=True)
            categories = [item[0] for item in sorted_items[:10]]
            counts = [item[1] for item in sorted_items[:10]]
        
        ax1.barh(categories, counts, color='#2c3e50')
        ax1.set_title('Top Categories by Question Count', fontsize=14, fontweight='bold')
        ax1.set_xlabel('Number of Questions')
        
        # ì§ˆë¬¸-ë‹µë³€ ê¸¸ì´ ë¶„í¬
        ax2.hist(stats['question_lengths'], bins=20, alpha=0.7, label='Questions', color='#3498db')
        ax2.hist(stats['answer_lengths'], bins=20, alpha=0.7, label='Answers', color='#e74c3c')
        ax2.set_title('Question vs Answer Length Distribution', fontsize=14, fontweight='bold')
        ax2.set_xlabel('Length (words)')
        ax2.set_ylabel('Frequency')
        ax2.legend()
        
        plt.tight_layout()
        plt.savefig(self.output_dir / 'figure2_detailed_analysis.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print("ğŸ“Š ê·¸ë˜í”„ ìƒì„± ì™„ë£Œ")
    
    def _create_tables(self, stats):
        """ë…¼ë¬¸ìš© í‘œ ìƒì„±"""
        # Table 1: ê¸°ë³¸ í†µê³„
        table1_content = f"""
Table 1: NetworkConfigQA Dataset Statistics

Characteristic                | Value
------------------------------|--------
Total Samples                 | {stats['total_samples']:,}
Training Samples               | {stats['train_samples']:,}
Validation Samples             | {stats['val_samples']:,}
Test Samples                   | {stats['test_samples']:,}
Categories                     | {len(stats['category_counts'])}
Complexity Levels              | {len(stats['complexity_counts'])}
Network Devices                | {stats['device_count']}
Topology-Specific Ratio        | {stats['topology_ratio']:.1%}
Avg Question Length (words)    | {stats['avg_question_length']:.1f}
Avg Answer Length (words)      | {stats['avg_answer_length']:.1f}
"""
        
        with open(self.output_dir / 'table1_basic_statistics.txt', 'w', encoding='utf-8') as f:
            f.write(table1_content)
        
        # Table 2: ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬
        table2_content = "Table 2: Category Distribution\\n\\n"
        table2_content += "Category | Count | Percentage\\n"
        table2_content += "---------|-------|----------\\n"
        
        sorted_categories = sorted(stats['category_counts'].items(), key=lambda x: x[1], reverse=True)
        for cat, count in sorted_categories:
            percentage = (count / stats['total_samples']) * 100
            table2_content += f"{cat} | {count} | {percentage:.1f}%\\n"
        
        with open(self.output_dir / 'table2_category_distribution.txt', 'w', encoding='utf-8') as f:
            f.write(table2_content)
        
        # Table 3: ë³µì¡ë„ë³„ ë¶„í¬
        table3_content = "Table 3: Complexity Distribution\\n\\n"
        table3_content += "Complexity | Count | Percentage\\n"
        table3_content += "-----------|-------|----------\\n"
        
        complexity_order = ['basic', 'analytical', 'synthetic', 'diagnostic', 'scenario']
        for comp in complexity_order:
            count = stats['complexity_counts'].get(comp, 0)
            percentage = (count / stats['total_samples']) * 100 if stats['total_samples'] > 0 else 0
            table3_content += f"{comp.title()} | {count} | {percentage:.1f}%\\n"
        
        with open(self.output_dir / 'table3_complexity_distribution.txt', 'w', encoding='utf-8') as f:
            f.write(table3_content)
        
        print("ğŸ“‹ í‘œ ìƒì„± ì™„ë£Œ")
    
    def _create_report(self, stats):
        """ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±"""
        report = f"""
# NetworkConfigQA Dataset Analysis Report

## Executive Summary
NetworkConfigQAëŠ” ë„¤íŠ¸ì›Œí¬ êµ¬ì„± íŒŒì‹±ì— íŠ¹í™”ëœ ë°ì´í„°ì…‹ìœ¼ë¡œ, ì‹¤ì œ ë„¤íŠ¸ì›Œí¬ í† í´ë¡œì§€ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.

## Key Statistics
- **ì´ ìƒ˜í”Œ ìˆ˜**: {stats['total_samples']:,}ê°œ
- **ë„¤íŠ¸ì›Œí¬ ì¥ë¹„ ìˆ˜**: {stats['device_count']}ê°œ
- **í† í´ë¡œì§€ íŠ¹í™” ë¹„ìœ¨**: {stats['topology_ratio']:.1%}
- **í‰ê·  ì§ˆë¬¸ ê¸¸ì´**: {stats['avg_question_length']:.1f} ë‹¨ì–´
- **í‰ê·  ë‹µë³€ ê¸¸ì´**: {stats['avg_answer_length']:.1f} ë‹¨ì–´

## Dataset Composition

### Data Split
- Training: {stats['train_samples']:,} ({stats['train_samples']/stats['total_samples']*100:.1f}%)
- Validation: {stats['val_samples']:,} ({stats['val_samples']/stats['total_samples']*100:.1f}%)
- Test: {stats['test_samples']:,} ({stats['test_samples']/stats['total_samples']*100:.1f}%)

### Question Focus
- Topology-Specific: {stats['topology_count']:,} ({stats['topology_ratio']:.1%})
- General Network: {stats['general_count']:,} ({(1-stats['topology_ratio']):.1%})

### Answer Types
"""
        
        for answer_type, count in stats['answer_type_counts'].items():
            percentage = (count / stats['total_samples']) * 100
            report += f"- {answer_type.title()}: {count:,} ({percentage:.1f}%)\\n"
        
        report += f"""

## Dataset Strengths for Network Configuration Parsing

1. **Real Topology Foundation**: ì‹¤ì œ ë„¤íŠ¸ì›Œí¬ ì¥ë¹„ ì„¤ì • íŒŒì¼ ê¸°ë°˜
2. **High Topology Focus**: ì „ì²´ ì§ˆë¬¸ì˜ {stats['topology_ratio']:.1%}ê°€ í† í´ë¡œì§€ íŠ¹í™”
3. **Multi-Level Complexity**: {len(stats['complexity_counts'])}ë‹¨ê³„ ë³µì¡ë„ ì§€ì›
4. **Balanced Generation**: Rule-based + LLM í•˜ì´ë¸Œë¦¬ë“œ ìƒì„±

## Research Applications

### Primary Use Cases
1. **LLM Fine-tuning**: ë„¤íŠ¸ì›Œí¬ êµ¬ì„± ì´í•´ ëŠ¥ë ¥ í–¥ìƒ
2. **Topology Parsing**: XML/ì„¤ì • íŒŒì¼ íŒŒì‹± ì„±ëŠ¥ í‰ê°€
3. **Network Analysis**: ìë™í™”ëœ ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ë„êµ¬ ê°œë°œ
4. **Educational**: ë„¤íŠ¸ì›Œí¬ ì—”ì§€ë‹ˆì–´ êµìœ¡ìš© í‰ê°€

### Evaluation Metrics
- **Exact Match**: ì •í™•í•œ ë‹µë³€ ì¼ì¹˜ë„
- **F1 Score**: ë¶€ë¶„ ì •ë‹µ ì¸ì • ì ìˆ˜
- **Topology Accuracy**: í† í´ë¡œì§€ íŠ¹í™” ì •í™•ë„
- **Complexity-wise Performance**: ë³µì¡ë„ë³„ ì„±ëŠ¥ ë¶„ì„

## Comparison with Existing Benchmarks

NetworkConfigQAì˜ ì°¨ë³„ì :
- **Domain Specificity**: ë„¤íŠ¸ì›Œí¬ êµ¬ì„± íŒŒì‹±ì— íŠ¹í™”
- **Real Data**: ì‹¤ì œ ìƒì‚° í™˜ê²½ ë„¤íŠ¸ì›Œí¬ ì„¤ì • ê¸°ë°˜
- **Topology Focus**: ì¼ë°˜ì ì¸ ë„¤íŠ¸ì›Œí¬ ì§€ì‹ì´ ì•„ë‹Œ íŠ¹ì • í† í´ë¡œì§€ ì´í•´ ì¤‘ì‹¬
- **Multi-modal**: ì„¤ì • íŒŒì¼ + ìì—°ì–´ ì§ˆì˜ì‘ë‹µ

## Files Generated
- `figure1_dataset_overview.png`: ë°ì´í„°ì…‹ êµ¬ì„± ê°œìš”
- `figure2_detailed_analysis.png`: ìƒì„¸ ë¶„ì„ ê·¸ë˜í”„
- `table1_basic_statistics.txt`: ê¸°ë³¸ í†µê³„í‘œ
- `table2_category_distribution.txt`: ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬
- `table3_complexity_distribution.txt`: ë³µì¡ë„ë³„ ë¶„í¬

## Recommended Paper Sections

### Abstract
"We present NetworkConfigQA, a specialized dataset for evaluating large language models on network configuration parsing tasks. The dataset contains {stats['total_samples']:,} question-answer pairs derived from real network topologies, with {stats['topology_ratio']:.1%} focusing on topology-specific understanding rather than general networking knowledge."

### Dataset Description
"NetworkConfigQA comprises {stats['total_samples']:,} samples across {len(stats['category_counts'])} categories and {len(stats['complexity_counts'])} complexity levels, generated from {stats['device_count']} real network devices..."

### Evaluation Setup  
"We evaluate models on exact match accuracy, F1 score, and topology-specific accuracy. The dataset is split into {stats['train_samples']:,}/{stats['val_samples']:,}/{stats['test_samples']:,} for train/validation/test..."
"""
        
        with open(self.output_dir / 'comprehensive_analysis_report.md', 'w', encoding='utf-8') as f:
            f.write(report)
        
        print("ğŸ“ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import sys
    
    dataset_path = "output/no_feedback/network_config_qa_dataset.json"
    
    if len(sys.argv) > 1:
        dataset_path = sys.argv[1]
    
    if not Path(dataset_path).exists():
        print(f"âŒ ë°ì´í„°ì…‹ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {dataset_path}")
        return
    
    analyzer = SimpleNetworkDatasetAnalyzer(dataset_path)
    stats = analyzer.generate_analysis()
    
    print("\\n" + "="*50)
    print("ğŸ“Š ì£¼ìš” í†µê³„ ìš”ì•½")
    print("="*50)
    print(f"ì´ ìƒ˜í”Œ ìˆ˜: {stats['total_samples']:,}")
    print(f"í† í´ë¡œì§€ íŠ¹í™” ë¹„ìœ¨: {stats['topology_ratio']:.1%}")
    print(f"í‰ê·  ì§ˆë¬¸ ê¸¸ì´: {stats['avg_question_length']:.1f} ë‹¨ì–´")
    print(f"ì¹´í…Œê³ ë¦¬ ìˆ˜: {len(stats['category_counts'])}")
    print(f"ë³µì¡ë„ ë ˆë²¨: {len(stats['complexity_counts'])}")

if __name__ == "__main__":
    main()
