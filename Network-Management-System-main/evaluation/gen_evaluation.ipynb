{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6410646",
   "metadata": {},
   "source": [
    "# Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b1c6425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Read the uploaded log file\n",
    "log_path = \"/workspace/jke/pipeline/pipeline_results_qwen_final_exprement_50.log\"\n",
    "\n",
    "# Extract Question and Final Answer pairs\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "with open(log_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Regex to capture Question and Final Answer blocks\n",
    "pattern = re.compile(r\"Question:\\s*(.*?)\\nFinal Answer:\\s*(.*?)(?=\\n=+)\", re.S)\n",
    "matches = pattern.findall(content)\n",
    "\n",
    "for q, a in matches:\n",
    "    questions.append(q.strip())\n",
    "    answers.append(a.strip())\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\"Question\": questions, \"Final Answer\": answers})\n",
    "\n",
    "# Save to CSV\n",
    "output_path = \"predict_50.csv\"\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4657614b",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e36fbce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: torch>=1.0.0 in /opt/conda/envs/jke/lib/python3.12/site-packages (from bert-score) (2.5.1)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /opt/conda/envs/jke/lib/python3.12/site-packages (from bert-score) (2.2.3)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /opt/conda/envs/jke/lib/python3.12/site-packages (from bert-score) (4.51.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/jke/lib/python3.12/site-packages (from bert-score) (1.26.4)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/jke/lib/python3.12/site-packages (from bert-score) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /opt/conda/envs/jke/lib/python3.12/site-packages (from bert-score) (4.66.5)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/jke/lib/python3.12/site-packages (from bert-score) (3.9.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/envs/jke/lib/python3.12/site-packages (from bert-score) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/envs/jke/lib/python3.12/site-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/jke/lib/python3.12/site-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/envs/jke/lib/python3.12/site-packages (from pandas>=1.0.1->bert-score) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/jke/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/jke/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/envs/jke/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/jke/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (80.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/envs/jke/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (1.13.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/envs/jke/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/jke/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/envs/jke/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (2024.6.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/envs/jke/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/conda/envs/jke/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (0.34.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/jke/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/jke/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/envs/jke/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/envs/jke/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (0.5.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/envs/jke/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=3.0.0->bert-score) (1.1.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/jke/lib/python3.12/site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/envs/jke/lib/python3.12/site-packages (from matplotlib->bert-score) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/jke/lib/python3.12/site-packages (from matplotlib->bert-score) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/envs/jke/lib/python3.12/site-packages (from matplotlib->bert-score) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/envs/jke/lib/python3.12/site-packages (from matplotlib->bert-score) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/envs/jke/lib/python3.12/site-packages (from matplotlib->bert-score) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/envs/jke/lib/python3.12/site-packages (from matplotlib->bert-score) (3.1.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/envs/jke/lib/python3.12/site-packages (from requests->bert-score) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/jke/lib/python3.12/site-packages (from requests->bert-score) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/jke/lib/python3.12/site-packages (from requests->bert-score) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/jke/lib/python3.12/site-packages (from requests->bert-score) (2025.1.31)\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "Installing collected packages: bert-score\n",
      "Successfully installed bert-score-0.3.13\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b03386f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting absl-py (from rouge-score)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: nltk in /opt/conda/envs/jke/lib/python3.12/site-packages (from rouge-score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/jke/lib/python3.12/site-packages (from rouge-score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/envs/jke/lib/python3.12/site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/envs/jke/lib/python3.12/site-packages (from nltk->rouge-score) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/envs/jke/lib/python3.12/site-packages (from nltk->rouge-score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/envs/jke/lib/python3.12/site-packages (from nltk->rouge-score) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/jke/lib/python3.12/site-packages (from nltk->rouge-score) (4.66.5)\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Building wheels for collected packages: rouge-score\n",
      "\u001b[33m  DEPRECATION: Building 'rouge-score' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'rouge-score'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24987 sha256=5b4a8b7e078650373a3ff9bdf76810643e331f44e3b0d971ce46caa076ccd446\n",
      "  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: absl-py, rouge-score\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [rouge-score]\n",
      "\u001b[1A\u001b[2KSuccessfully installed absl-py-2.3.1 rouge-score-0.1.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d4bf9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평가 결과 저장 완료 → eval_results_predict_1.csv\n",
      "평가 결과 저장 완료 → eval_results_predict_5.csv\n",
      "평가 결과 저장 완료 → eval_results_predict_10.csv\n",
      "평가 결과 저장 완료 → eval_results_predict_20.csv\n",
      "평가 결과 저장 완료 → eval_results_predict_50.csv\n",
      "전체 결과 요약 저장 완료 → eval_results_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from bert_score import score\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# 간단 문자열 정규화 (공백 압축 + 따옴표/공백 제거)\n",
    "_ws = re.compile(r\"\\s+\")\n",
    "def _norm(s: pd.Series) -> pd.Series:\n",
    "    s = s.astype(str).fillna(\"\")\n",
    "    s = s.map(lambda x: x.strip().strip('\"').strip(\"'\"))\n",
    "    s = s.map(lambda x: _ws.sub(\" \", x))\n",
    "    return s.str.strip()\n",
    "\n",
    "def eval_from_two_csv(\n",
    "    gt_path: str,\n",
    "    pred_path: str,\n",
    "    merge_on: str = \"id\",\n",
    "    lang: str = \"ko\",\n",
    "    use_xlm: bool = True,\n",
    "    save_path: str = \"evaluation_results.json\"  # 저장 경로 (확장자 .json/.csv 둘 다 가능)\n",
    "):\n",
    "    # ===== 1) 데이터 로드 및 merge =====\n",
    "    df_gt = pd.read_csv(gt_path)\n",
    "    df_pred = pd.read_csv(pred_path)\n",
    "\n",
    "    df = pd.merge(df_gt, df_pred, on=merge_on, how=\"inner\")\n",
    "\n",
    "    if \"ground_truth\" not in df.columns:\n",
    "        raise KeyError(\"ground_truth 컬럼이 필요합니다 (test.csv).\")\n",
    "    if \"Final Answer\" not in df.columns:\n",
    "        raise KeyError(\"prediction CSV에 'Final Answer' 컬럼이 필요합니다.\")\n",
    "\n",
    "    gts   = df[\"ground_truth\"].astype(str).fillna(\"\").tolist()\n",
    "    preds = df[\"Final Answer\"].astype(str).fillna(\"\").tolist()\n",
    "\n",
    "    # ===== 2) BERTScore =====\n",
    "    if use_xlm:\n",
    "        P, R, F1 = score(preds, gts, model_type=\"xlm-roberta-large\")\n",
    "    else:\n",
    "        P, R, F1 = score(preds, gts, lang=lang)\n",
    "\n",
    "    # ===== 3) Exact Match =====\n",
    "    gt_norm = _norm(df[\"ground_truth\"]).str.lower()\n",
    "    pr_norm = _norm(df[\"Final Answer\"]).str.lower()\n",
    "    exact_match = (gt_norm == pr_norm).astype(int)\n",
    "    exact_match_accuracy = float(exact_match.mean()) if len(exact_match) else 0.0\n",
    "\n",
    "    # ===== 4) ROUGE (Precision, Recall, F1) =====\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1','rouge2','rougeL'], use_stemmer=True)\n",
    "\n",
    "    rouge_scores = {\"rouge1\": {\"p\":[], \"r\":[], \"f\":[]},\n",
    "                    \"rouge2\": {\"p\":[], \"r\":[], \"f\":[]},\n",
    "                    \"rougeL\": {\"p\":[], \"r\":[], \"f\":[]}}\n",
    "\n",
    "    for pred, gt in zip(preds, gts):\n",
    "        scores = scorer.score(gt, pred)\n",
    "        for k in [\"rouge1\",\"rouge2\",\"rougeL\"]:\n",
    "            rouge_scores[k][\"p\"].append(scores[k].precision)\n",
    "            rouge_scores[k][\"r\"].append(scores[k].recall)\n",
    "            rouge_scores[k][\"f\"].append(scores[k].fmeasure)\n",
    "\n",
    "    rouge_summary = {}\n",
    "    for k in rouge_scores:\n",
    "        rouge_summary[f\"{k}_precision\"] = sum(rouge_scores[k][\"p\"]) / len(rouge_scores[k][\"p\"])\n",
    "        rouge_summary[f\"{k}_recall\"]    = sum(rouge_scores[k][\"r\"]) / len(rouge_scores[k][\"r\"])\n",
    "        rouge_summary[f\"{k}_f1\"]        = sum(rouge_scores[k][\"f\"]) / len(rouge_scores[k][\"f\"])\n",
    "\n",
    "    # ===== 결과 dict =====\n",
    "    results = {\n",
    "        \"bert_score_precision\": P.mean().item(),\n",
    "        \"bert_score_recall\": R.mean().item(),\n",
    "        \"bert_score_f1\": F1.mean().item(),\n",
    "        \"exact_match_accuracy\": exact_match_accuracy,\n",
    "        **rouge_summary\n",
    "    }\n",
    "\n",
    "    # ===== 결과 저장 =====\n",
    "    if save_path.endswith(\".json\"):\n",
    "        with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "    elif save_path.endswith(\".csv\"):\n",
    "        pd.DataFrame([results]).to_csv(save_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(f\"평가 결과 저장 완료 → {save_path}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# 평가할 prediction 파일들\n",
    "prediction_files = [\n",
    "    \"predict_1.csv\",\n",
    "    \"predict_5.csv\",\n",
    "    \"predict_10.csv\",\n",
    "    \"predict_20.csv\",\n",
    "    \"predict_50.csv\",\n",
    "]\n",
    "\n",
    "# ground truth 파일\n",
    "gt_file = \"test.csv\"\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for pred_file in prediction_files:\n",
    "    # 저장 파일명 (ex: eval_results_predict_1.csv)\n",
    "    base_name = os.path.splitext(os.path.basename(pred_file))[0]\n",
    "    save_csv = f\"eval_results_{base_name}.csv\"\n",
    "\n",
    "    results = eval_from_two_csv(\n",
    "        gt_path=gt_file,\n",
    "        pred_path=pred_file,\n",
    "        merge_on=\"question\",   # id 기준이면 \"id\"로 바꿔주세요\n",
    "        save_path=save_csv\n",
    "    )\n",
    "\n",
    "    # 어떤 prediction 결과인지 구분 위해 이름 추가\n",
    "    results[\"prediction_file\"] = pred_file\n",
    "    all_results.append(results)\n",
    "\n",
    "# 여러 결과를 하나의 CSV로 합치기\n",
    "summary_path = \"eval_results_summary.csv\"\n",
    "pd.DataFrame(all_results).to_csv(summary_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"전체 결과 요약 저장 완료 → {summary_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00210e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.read_csv(\"eval_results_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c221f8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bert_score_precision</th>\n",
       "      <th>bert_score_recall</th>\n",
       "      <th>bert_score_f1</th>\n",
       "      <th>exact_match_accuracy</th>\n",
       "      <th>rouge1_precision</th>\n",
       "      <th>rouge1_recall</th>\n",
       "      <th>rouge1_f1</th>\n",
       "      <th>rouge2_precision</th>\n",
       "      <th>rouge2_recall</th>\n",
       "      <th>rouge2_f1</th>\n",
       "      <th>rougeL_precision</th>\n",
       "      <th>rougeL_recall</th>\n",
       "      <th>rougeL_f1</th>\n",
       "      <th>prediction_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.827405</td>\n",
       "      <td>0.863926</td>\n",
       "      <td>0.844023</td>\n",
       "      <td>0.151246</td>\n",
       "      <td>0.195149</td>\n",
       "      <td>0.470792</td>\n",
       "      <td>0.199681</td>\n",
       "      <td>0.051308</td>\n",
       "      <td>0.105770</td>\n",
       "      <td>0.053191</td>\n",
       "      <td>0.194412</td>\n",
       "      <td>0.469515</td>\n",
       "      <td>0.199210</td>\n",
       "      <td>predict_1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.825578</td>\n",
       "      <td>0.864199</td>\n",
       "      <td>0.843278</td>\n",
       "      <td>0.161922</td>\n",
       "      <td>0.216157</td>\n",
       "      <td>0.503312</td>\n",
       "      <td>0.218037</td>\n",
       "      <td>0.075978</td>\n",
       "      <td>0.141788</td>\n",
       "      <td>0.075283</td>\n",
       "      <td>0.215610</td>\n",
       "      <td>0.501516</td>\n",
       "      <td>0.217499</td>\n",
       "      <td>predict_5.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.832851</td>\n",
       "      <td>0.870039</td>\n",
       "      <td>0.849894</td>\n",
       "      <td>0.197509</td>\n",
       "      <td>0.252376</td>\n",
       "      <td>0.538728</td>\n",
       "      <td>0.255308</td>\n",
       "      <td>0.078885</td>\n",
       "      <td>0.139305</td>\n",
       "      <td>0.075671</td>\n",
       "      <td>0.251375</td>\n",
       "      <td>0.537083</td>\n",
       "      <td>0.254545</td>\n",
       "      <td>predict_10.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.837923</td>\n",
       "      <td>0.875247</td>\n",
       "      <td>0.854887</td>\n",
       "      <td>0.204626</td>\n",
       "      <td>0.292003</td>\n",
       "      <td>0.574528</td>\n",
       "      <td>0.294936</td>\n",
       "      <td>0.093867</td>\n",
       "      <td>0.145926</td>\n",
       "      <td>0.088286</td>\n",
       "      <td>0.289240</td>\n",
       "      <td>0.569557</td>\n",
       "      <td>0.292050</td>\n",
       "      <td>predict_20.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.843506</td>\n",
       "      <td>0.876638</td>\n",
       "      <td>0.858485</td>\n",
       "      <td>0.256228</td>\n",
       "      <td>0.347771</td>\n",
       "      <td>0.613358</td>\n",
       "      <td>0.349879</td>\n",
       "      <td>0.098050</td>\n",
       "      <td>0.148343</td>\n",
       "      <td>0.096073</td>\n",
       "      <td>0.343115</td>\n",
       "      <td>0.607663</td>\n",
       "      <td>0.345485</td>\n",
       "      <td>predict_50.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bert_score_precision  bert_score_recall  bert_score_f1  \\\n",
       "0              0.827405           0.863926       0.844023   \n",
       "1              0.825578           0.864199       0.843278   \n",
       "2              0.832851           0.870039       0.849894   \n",
       "3              0.837923           0.875247       0.854887   \n",
       "4              0.843506           0.876638       0.858485   \n",
       "\n",
       "   exact_match_accuracy  rouge1_precision  rouge1_recall  rouge1_f1  \\\n",
       "0              0.151246          0.195149       0.470792   0.199681   \n",
       "1              0.161922          0.216157       0.503312   0.218037   \n",
       "2              0.197509          0.252376       0.538728   0.255308   \n",
       "3              0.204626          0.292003       0.574528   0.294936   \n",
       "4              0.256228          0.347771       0.613358   0.349879   \n",
       "\n",
       "   rouge2_precision  rouge2_recall  rouge2_f1  rougeL_precision  \\\n",
       "0          0.051308       0.105770   0.053191          0.194412   \n",
       "1          0.075978       0.141788   0.075283          0.215610   \n",
       "2          0.078885       0.139305   0.075671          0.251375   \n",
       "3          0.093867       0.145926   0.088286          0.289240   \n",
       "4          0.098050       0.148343   0.096073          0.343115   \n",
       "\n",
       "   rougeL_recall  rougeL_f1 prediction_file  \n",
       "0       0.469515   0.199210   predict_1.csv  \n",
       "1       0.501516   0.217499   predict_5.csv  \n",
       "2       0.537083   0.254545  predict_10.csv  \n",
       "3       0.569557   0.292050  predict_20.csv  \n",
       "4       0.607663   0.345485  predict_50.csv  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62d4857",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jke",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
