{
    "gpt-4": {
        "provider": "openai",
        "model_name": "gpt-4",
        "max_tokens": 4096,
        "temperature": 0.0,
        "api_key": null,
        "description": "OpenAI GPT-4 - 최고 성능 범용 모델"
    },
    "gpt-4-turbo": {
        "provider": "openai",
        "model_name": "gpt-4-0125-preview",
        "max_tokens": 4096,
        "temperature": 0.0,
        "api_key": null,
        "description": "OpenAI GPT-4 Turbo - 빠른 성능과 긴 컨텍스트"
    },
    "gpt-3.5-turbo": {
        "provider": "openai",
        "model_name": "gpt-3.5-turbo",
        "max_tokens": 4096,
        "temperature": 0.0,
        "api_key": null,
        "description": "OpenAI GPT-3.5 Turbo - 비용 효율적"
    },
    "claude-3-opus": {
        "provider": "anthropic",
        "model_name": "claude-3-opus-20240229",
        "max_tokens": 4096,
        "temperature": 0.0,
        "api_key": null,
        "description": "Anthropic Claude 3 Opus - 최고 성능"
    },
    "claude-3-sonnet": {
        "provider": "anthropic",
        "model_name": "claude-3-sonnet-20240229",
        "max_tokens": 4096,
        "temperature": 0.0,
        "api_key": null,
        "description": "Anthropic Claude 3 Sonnet - 균형잡힌 성능"
    },
    "claude-3-haiku": {
        "provider": "anthropic",
        "model_name": "claude-3-haiku-20240307",
        "max_tokens": 4096,
        "temperature": 0.0,
        "api_key": null,
        "description": "Anthropic Claude 3 Haiku - 빠른 응답"
    },
    "llama-2-7b-chat": {
        "provider": "huggingface",
        "model_name": "meta-llama/Llama-2-7b-chat-hf",
        "max_tokens": 2048,
        "temperature": 0.0,
        "device": "cuda",
        "description": "Meta Llama 2 7B Chat - 오픈소스 모델"
    },
    "llama-2-13b-chat": {
        "provider": "huggingface",
        "model_name": "meta-llama/Llama-2-13b-chat-hf",
        "max_tokens": 2048,
        "temperature": 0.0,
        "device": "cuda",
        "description": "Meta Llama 2 13B Chat - 더 큰 오픈소스 모델"
    },
    "qwen-7b-chat": {
        "provider": "ollama",
        "model_name": "qwen:7b-chat",
        "base_url": "http://localhost:11434",
        "max_tokens": 2048,
        "temperature": 0.0,
        "description": "Alibaba Qwen 7B Chat - 로컬 실행"
    },
    "qwen-14b-chat": {
        "provider": "ollama",
        "model_name": "qwen:14b-chat",
        "base_url": "http://localhost:11434",
        "max_tokens": 2048,
        "temperature": 0.0,
        "description": "Alibaba Qwen 14B Chat - 더 큰 로컬 모델"
    },
    "mistral-7b": {
        "provider": "ollama",
        "model_name": "mistral:7b",
        "base_url": "http://localhost:11434",
        "max_tokens": 2048,
        "temperature": 0.0,
        "description": "Mistral 7B - 효율적인 오픈소스 모델"
    },
    "codellama-7b": {
        "provider": "ollama",
        "model_name": "codellama:7b",
        "base_url": "http://localhost:11434",
        "max_tokens": 2048,
        "temperature": 0.0,
        "description": "Code Llama 7B - 코드 특화 모델"
    }
}