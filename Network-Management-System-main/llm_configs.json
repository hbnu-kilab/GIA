[
    {
        "name": "gpt-4o-mini",
        "model_id": "gpt-4o-mini",
        "api_key": null,
        "max_tokens": 2000,
        "temperature": 0.1,
        "local": false
    },
    {
        "name": "gpt-4o",
        "model_id": "gpt-4o",
        "api_key": null,
        "max_tokens": 2000,
        "temperature": 0.1,
        "local": false
    },
    {
        "name": "claude-3-haiku",
        "model_id": "claude-3-haiku-20240307",
        "api_key": null,
        "max_tokens": 2000,
        "temperature": 0.1,
        "local": false
    },
    {
        "name": "claude-3-sonnet",
        "model_id": "claude-3-sonnet-20240229",
        "api_key": null,
        "max_tokens": 2000,
        "temperature": 0.1,
        "local": false
    },
    {
        "name": "llama-3-8b",
        "model_id": "meta-llama/Meta-Llama-3-8B-Instruct",
        "local": true,
        "max_tokens": 2000,
        "temperature": 0.1,
        "device": "cuda"
    },
    {
        "name": "llama-3-70b",
        "model_id": "meta-llama/Meta-Llama-3-70B-Instruct",
        "local": true,
        "max_tokens": 2000,
        "temperature": 0.1,
        "device": "cuda"
    },
    {
        "name": "qwen-2.5-7b",
        "model_id": "Qwen/Qwen2.5-7B-Instruct",
        "local": true,
        "max_tokens": 2000,
        "temperature": 0.1,
        "device": "cuda"
    },
    {
        "name": "qwen-2.5-14b",
        "model_id": "Qwen/Qwen2.5-14B-Instruct",
        "local": true,
        "max_tokens": 2000,
        "temperature": 0.1,
        "device": "cuda"
    },
    {
        "name": "gemma-7b",
        "model_id": "google/gemma-7b-it",
        "local": true,
        "max_tokens": 2000,
        "temperature": 0.1,
        "device": "cuda"
    },
    {
        "name": "mixtral-8x7b",
        "model_id": "mistralai/Mixtral-8x7B-Instruct-v0.1",
        "local": true,
        "max_tokens": 2000,
        "temperature": 0.1,
        "device": "cuda"
    }
]