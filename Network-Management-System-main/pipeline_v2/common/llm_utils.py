from __future__ import annotations

from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional
from io import StringIO
import sys
import json
import os
import time
import random
import threading
from collections import defaultdict

from openai import OpenAI, RateLimitError


class ExperimentLogger:
    """ì‹¤í—˜ ë¡œê·¸/ê²°ê³¼/LLM í˜¸ì¶œ ë‚´ì—­ì„ êµ¬ì¡°ì ìœ¼ë¡œ ê´€ë¦¬"""

    def __init__(self, experiment_name: str, base_dir: str = "experiment_results"):
        self.experiment_name = experiment_name
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.base_dir = Path(base_dir)

        # ë””ë ‰í† ë¦¬ êµ¬ì„± - base_dirì„ ì§ì ‘ ì‚¬ìš© (ì¶”ê°€ íƒ€ì„ìŠ¤íƒ¬í”„ í´ë” ìƒì„±í•˜ì§€ ì•ŠìŒ)
        self.exp_dir = self.base_dir
        self.logs_dir = self.exp_dir / "logs"
        self.results_dir = self.exp_dir / "results"
        self.llm_history_dir = self.exp_dir / "llm_history"
        self.console_dir = self.exp_dir / "console_output"
        for d in [self.exp_dir, self.logs_dir, self.results_dir, self.llm_history_dir, self.console_dir]:
            d.mkdir(parents=True, exist_ok=True)

        self.console_buffer = StringIO()
        self.original_stdout = sys.stdout
        self.llm_calls: List[Dict] = []
        
        # ì§ˆë¬¸ë³„ ID ì¶”ì 
        self.current_question_id: Optional[int] = None
        self.question_call_counters: Dict[int, Dict[str, int]] = {}

        print(f"[INFO] Experiment '{experiment_name}' initialized")
        print(f"[INFO] Results dir: {self.exp_dir}")

    # ì½˜ì†” ìº¡ì²˜
    def start_console_capture(self):
        sys.stdout = self.console_buffer

    def stop_console_capture(self):
        sys.stdout = self.original_stdout
        content = self.console_buffer.getvalue()
        if content:
            out_file = self.console_dir / f"console_{self.timestamp}.txt"
            out_file.write_text(content, encoding="utf-8")
            print(f"[INFO] Console output saved to: {out_file}")
        self.console_buffer = StringIO()

    # ì§ˆë¬¸ ID ê´€ë¦¬
    def set_current_question_id(self, question_id: int):
        """í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ì§ˆë¬¸ ID ì„¤ì •"""
        self.current_question_id = question_id
        if question_id not in self.question_call_counters:
            self.question_call_counters[question_id] = {}

    # ì €ì¥/ë¡œê¹…
    def log_llm_call(
        self,
        call_type: str,
        prompt: str,
        response: str,
        model: str = "gpt-4o-mini",
        metadata: Optional[Dict] = None,
    ) -> None:
        rec = {
            "timestamp": datetime.now().isoformat(),
            "call_type": call_type,
            "model": model,
            "prompt": prompt,
            "response": response,
            "metadata": metadata or {},
            "question_id": self.current_question_id,
        }
        self.llm_calls.append(rec)
        
        # ì§ˆë¬¸ë³„ íŒŒì¼ ë„¤ì´ë°
        if self.current_question_id is not None:
            question_id = self.current_question_id
            # ê°™ì€ ì§ˆë¬¸ ë‚´ì—ì„œ call_typeë³„ ìˆœë²ˆ ê´€ë¦¬
            if call_type not in self.question_call_counters[question_id]:
                self.question_call_counters[question_id][call_type] = 0
            self.question_call_counters[question_id][call_type] += 1
            
            call_num = self.question_call_counters[question_id][call_type]
            if call_num > 1:
                # ê°™ì€ íƒ€ì…ì´ ì—¬ëŸ¬ ë²ˆ í˜¸ì¶œë˜ëŠ” ê²½ìš° ìˆœë²ˆ ì¶”ê°€
                call_file = self.llm_history_dir / f"q{question_id:03d}_{call_type}_{call_num}.json"
            else:
                # ì²« ë²ˆì§¸ í˜¸ì¶œì€ ìˆœë²ˆ ì—†ì´
                call_file = self.llm_history_dir / f"q{question_id:03d}_{call_type}.json"
        else:
            # fallback to old naming
            call_file = self.llm_history_dir / f"llm_call_{len(self.llm_calls):03d}_{call_type}.json"
            
        call_file.write_text(json.dumps(rec, ensure_ascii=False, indent=2), encoding="utf-8")

    def save_detailed_log(self, log_data: List[Dict], filename: str | None = None):
        if not filename:
            filename = f"detailed_log_{self.timestamp}.json"
        path = self.logs_dir / filename
        path.write_text(json.dumps(log_data, ensure_ascii=False, indent=2), encoding="utf-8")
        print(f"[INFO] Detailed log saved: {path}")

    def save_results(self, results: Dict, filename: str | None = None):
        if not filename:
            filename = f"results_{self.timestamp}.json"
        path = self.results_dir / filename
        path.write_text(json.dumps(results, ensure_ascii=False, indent=2), encoding="utf-8")
        print(f"[INFO] Results saved: {path}")

    def save_llm_history_summary(self):
        stats: Dict[str, Dict] = {}
        for c in self.llm_calls:
            t = c["call_type"]
            stats.setdefault(t, {"count": 0, "total_prompt_length": 0, "total_response_length": 0})
            stats[t]["count"] += 1
            stats[t]["total_prompt_length"] += len(c["prompt"]) if c.get("prompt") else 0
            stats[t]["total_response_length"] += len(c["response"]) if c.get("response") else 0
        summary = {
            "total_calls": len(self.llm_calls),
            "call_types": list(stats.keys()),
            "statistics": stats,
            "first_call": self.llm_calls[0]["timestamp"] if self.llm_calls else None,
            "last_call": self.llm_calls[-1]["timestamp"] if self.llm_calls else None,
        }
        path = self.llm_history_dir / f"llm_history_summary_{self.timestamp}.json"
        path.write_text(json.dumps(summary, ensure_ascii=False, indent=2), encoding="utf-8")
        print(f"[INFO] LLM history summary saved: {path}")

    def finalize_experiment(self):
        self.stop_console_capture()
        self.save_llm_history_summary()
        meta = {
            "experiment_name": self.experiment_name,
            "timestamp": self.timestamp,
            "total_llm_calls": len(self.llm_calls),
            "directories": {
                "base": str(self.exp_dir),
                "logs": str(self.logs_dir),
                "results": str(self.results_dir),
                "llm_history": str(self.llm_history_dir),
                "console": str(self.console_dir),
            },
        }
        (self.exp_dir / "experiment_metadata.json").write_text(
            json.dumps(meta, ensure_ascii=False, indent=2), encoding="utf-8"
        )
        print("=" * 70)
        print(f"Experiment '{self.experiment_name}' complete â†’ {self.exp_dir}")
        print("=" * 70)


class MultiKeyOpenAIClient:
    """ë‹¤ì¤‘ API í‚¤ë¥¼ ì‚¬ìš©í•œ ìŠ¤ë§ˆíŠ¸ ë¡œë“œ ë°¸ëŸ°ì‹± OpenAI í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self, api_keys: List[str]):
        if not api_keys:
            raise ValueError("âŒ API í‚¤ê°€ í•˜ë‚˜ë„ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        self.api_keys = api_keys
        self.clients = [OpenAI(api_key=key) for key in api_keys]
        
        # ê° í‚¤ë³„ ìƒíƒœ ì¶”ì 
        self.key_stats = defaultdict(lambda: {
            'total_calls': 0,
            'rate_limited': 0,
            'last_rate_limit': 0,
            'avg_response_time': 0.0,
            'error_count': 0
        })
        
        # Round-robin ì¸ë±ìŠ¤
        self.current_index = 0
        self.lock = threading.Lock()
        
        print(f"ğŸ”„ MultiKey í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”: {len(api_keys)}ê°œ í‚¤")
    
    def _get_next_client(self) -> tuple[OpenAI, int]:
        """ë‹¤ìŒ ì‚¬ìš©í•  í´ë¼ì´ì–¸íŠ¸ì™€ ì¸ë±ìŠ¤ ë°˜í™˜ (ìŠ¤ë§ˆíŠ¸ ì„ íƒ)"""
        with self.lock:
            current_time = time.time()
            
            # 1. Rate limitì´ ìµœê·¼ì— ê±¸ë¦° í‚¤ë“¤ ì œì™¸ (5ë¶„ ì´ë‚´)
            available_indices = []
            for i, key in enumerate(self.api_keys):
                last_rate_limit = self.key_stats[key]['last_rate_limit']
                if current_time - last_rate_limit > 300:  # 5ë¶„ = 300ì´ˆ
                    available_indices.append(i)
            
            if not available_indices:
                # ëª¨ë“  í‚¤ê°€ rate limitì— ê±¸ë ¸ë‹¤ë©´, ì „ì²´ í‚¤ ì¤‘ì—ì„œ ì„ íƒ
                available_indices = list(range(len(self.api_keys)))
                print("âš ï¸ ëª¨ë“  í‚¤ê°€ ìµœê·¼ rate limitì— ê±¸ë ¸ìŠµë‹ˆë‹¤. ê°€ì¥ ì˜¤ë˜ëœ í‚¤ ì‚¬ìš©...")
            
            # 2. ì—ëŸ¬ê°€ ê°€ì¥ ì ì€ í‚¤ ìš°ì„  ì„ íƒ
            best_index = min(available_indices, 
                           key=lambda i: self.key_stats[self.api_keys[i]]['error_count'])
            
            # 3. Round-robinìœ¼ë¡œ ë¶„ì‚° (ë™ì¼ ì—ëŸ¬ ìˆ˜ì¸ ê²½ìš°)
            if len(available_indices) > 1:
                self.current_index = (self.current_index + 1) % len(available_indices)
                best_index = available_indices[self.current_index]
            
            return self.clients[best_index], best_index
    
    def _update_stats(self, key_index: int, success: bool, response_time: float, was_rate_limited: bool = False):
        """í‚¤ë³„ í†µê³„ ì—…ë°ì´íŠ¸"""
        key = self.api_keys[key_index]
        stats = self.key_stats[key]
        
        stats['total_calls'] += 1
        if was_rate_limited:
            stats['rate_limited'] += 1
            stats['last_rate_limit'] = time.time()
        
        if not success:
            stats['error_count'] += 1
        
        # ì´ë™ í‰ê· ìœ¼ë¡œ ì‘ë‹µ ì‹œê°„ ê³„ì‚°
        if stats['avg_response_time'] == 0:
            stats['avg_response_time'] = response_time
        else:
            stats['avg_response_time'] = (stats['avg_response_time'] * 0.9) + (response_time * 0.1)
    
    def chat_completions_create(self, **kwargs):
        """ë‹¤ì¤‘ í‚¤ë¡œ chat completions ìš”ì²­"""
        max_retries = len(self.api_keys) * 2  # ëª¨ë“  í‚¤ë¥¼ 2ë²ˆì”© ì‹œë„
        
        for attempt in range(max_retries):
            client, key_index = self._get_next_client()
            start_time = time.time()
            
            try:
                response = client.chat.completions.create(**kwargs)
                response_time = time.time() - start_time
                self._update_stats(key_index, True, response_time)
                
                # ì„±ê³µ ë¡œê¹…
                key_suffix = self.api_keys[key_index][-8:]  # ë§ˆì§€ë§‰ 8ìë¦¬ë§Œ
                if attempt > 0:  # ì¬ì‹œë„ í›„ ì„±ê³µì¸ ê²½ìš°ì—ë§Œ ë¡œê·¸
                    print(f"âœ… API í˜¸ì¶œ ì„±ê³µ (í‚¤: ...{key_suffix}, ì¬ì‹œë„: {attempt}, ì‹œê°„: {response_time:.2f}s)")
                
                return response
                
            except RateLimitError as e:
                response_time = time.time() - start_time
                self._update_stats(key_index, False, response_time, was_rate_limited=True)
                
                key_suffix = self.api_keys[key_index][-8:]
                print(f"âš ï¸ Rate limit (í‚¤: ...{key_suffix}) - ë‹¤ë¥¸ í‚¤ë¡œ ì¬ì‹œë„... ({attempt+1}/{max_retries})")
                
                # Rate limitì¸ ê²½ìš° ë°”ë¡œ ë‹¤ë¥¸ í‚¤ë¡œ ì‹œë„
                continue
                
            except Exception as e:
                response_time = time.time() - start_time
                self._update_stats(key_index, False, response_time)
                
                key_suffix = self.api_keys[key_index][-8:]
                print(f"âŒ API ì˜¤ë¥˜ (í‚¤: ...{key_suffix}): {str(e)[:100]}...")
                
                # ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë©´ ê³„ì†
                if attempt < max_retries - 1:
                    time.sleep(min(2 ** (attempt // len(self.api_keys)), 10))  # ì§€ìˆ˜ ë°±ì˜¤í”„ (ìµœëŒ€ 10ì´ˆ)
                    continue
                else:
                    raise e
        
        raise Exception(f"ëª¨ë“  API í‚¤ ({len(self.api_keys)}ê°œ)ì—ì„œ ìš”ì²­ ì‹¤íŒ¨")
    
    def print_stats(self):
        """ê° í‚¤ë³„ ì‚¬ìš© í†µê³„ ì¶œë ¥"""
        print("\nğŸ“Š API í‚¤ë³„ ì‚¬ìš© í†µê³„:")
        print("-" * 80)
        print("í‚¤ (ë§ˆì§€ë§‰8ì)  | í˜¸ì¶œìˆ˜ | Rateì œí•œ | ì—ëŸ¬ìˆ˜ | í‰ê· ì‘ë‹µì‹œê°„ | ìƒíƒœ")
        print("-" * 80)
        
        current_time = time.time()
        for i, key in enumerate(self.api_keys):
            stats = self.key_stats[key]
            key_suffix = key[-8:]
            
            # ìƒíƒœ í‘œì‹œ
            if current_time - stats['last_rate_limit'] < 300:
                status = "ğŸ”´ ì œí•œì¤‘"
            elif stats['error_count'] > stats['total_calls'] * 0.1:
                status = "ğŸŸ¡ ë¶ˆì•ˆì •"
            else:
                status = "ğŸŸ¢ ì •ìƒ"
            
            print(f"...{key_suffix}        | {stats['total_calls']:6d} | {stats['rate_limited']:8d} | {stats['error_count']:6d} | {stats['avg_response_time']:10.2f}s | {status}")
        
        print("-" * 80)


class TrackedOpenAIClient:
    """LLM í˜¸ì¶œ ë¡œê¹…ì„ ì¶”ê°€í•œ OpenAI í´ë¼ì´ì–¸íŠ¸ (ë‹¤ì¤‘ í‚¤ ì§€ì›)"""

    def __init__(self, logger: ExperimentLogger):
        from config import OPENAI_API_KEYS
        
        if len(OPENAI_API_KEYS) > 1:
            self.client = MultiKeyOpenAIClient(OPENAI_API_KEYS)
            self.is_multi_key = True
            print(f"ğŸš€ ë‹¤ì¤‘ í‚¤ ëª¨ë“œ í™œì„±í™”: {len(OPENAI_API_KEYS)}ê°œ í‚¤")
        else:
            self.client = OpenAI(api_key=OPENAI_API_KEYS[0])
            self.is_multi_key = False
            print(f"ğŸ”‘ ë‹¨ì¼ í‚¤ ëª¨ë“œ")
        
        self.logger = logger
        self.call_count = 0

    def chat_completions_create(self, call_type: str, **kwargs):
        self.call_count += 1
        
        # ë©”ì‹œì§€ í¬ë§·íŒ…
        messages = kwargs.get("messages", [])
        prompt = "\n".join([f"{m['role']}: {m['content']}" for m in messages])

        # API í˜¸ì¶œ
        # OpenAI chat.completionsëŠ” metadata ì¸ìë¥¼ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì œê±°
        forwarded_kwargs = dict(kwargs)
        if "metadata" in forwarded_kwargs:
            forwarded_kwargs.pop("metadata", None)
        if self.is_multi_key:
            # ë‹¤ì¤‘ í‚¤ ì‚¬ìš©
            resp = self.client.chat_completions_create(**forwarded_kwargs)
        else:
            # ë‹¨ì¼ í‚¤ ì‚¬ìš© (ê¸°ì¡´ ë°©ì‹)
            resp = self.client.chat.completions.create(**forwarded_kwargs)
        
        # ì‘ë‹µ ì¶”ì¶œ
        text = resp.choices[0].message.content if resp.choices else ""
        
        # ë©”íƒ€ë°ì´í„° ìƒì„±
        meta = {
            "model": kwargs.get("model", "unknown"),
            "temperature": kwargs.get("temperature", "unknown"),
            "prompt_tokens": len(prompt.split()) if prompt else 0,
            "response_tokens": len(text.split()) if text else 0,
            "multi_key_mode": self.is_multi_key,
            "total_api_calls": self.call_count
        }
        # ì™¸ë¶€ì—ì„œ ì „ë‹¬ëœ ë©”íƒ€ë°ì´í„° ë³‘í•©(ì»¨í…ìŠ¤íŠ¸ ì¶”ì  ë“± ë””ë²„ê¹…ìš©)
        try:
            extra = kwargs.get("metadata")
            if isinstance(extra, dict):
                # ë¬¸ìì—´í™”ë¡œ JSON ì§ë ¬í™” ì•ˆì „ ë³´ì¥
                safe_extra = {}
                for k, v in extra.items():
                    try:
                        safe_extra[str(k)] = v if isinstance(v, (str, int, float, bool, type(None))) else str(v)
                    except Exception:
                        safe_extra[str(k)] = str(v)
                meta.update(safe_extra)
        except Exception:
            pass
        
        # ë¡œê¹…
        self.logger.log_llm_call(call_type, prompt, text, kwargs.get("model", "unknown"), meta)
        
        return resp
    
    def print_summary(self):
        """ì‚¬ìš© ìš”ì•½ ì¶œë ¥"""
        print(f"\nğŸ“ˆ ì „ì²´ API í˜¸ì¶œ ìˆ˜: {self.call_count}")
        if self.is_multi_key:
            self.client.print_stats()
